{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dropout, Activation, Dense, Flatten\n",
    "from keras.layers.convolutional import Convolution1D,AveragePooling1D,MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mn2_C = (pd.read_pickle('Mn2_Larger_Clean_Thin.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mn3_C = (pd.read_pickle('Mn3_Larger_Clean_Thin.pkl'))\n",
    "Mn4_C = (pd.read_pickle('Mn4_Larger_Clean_Thin.pkl'))\n",
    "Mn_All = (Mn2_C.append(Mn3_C, ignore_index=True)).append(Mn4_C, ignore_index=True)\n",
    "Mn_All = np.array(Mn_All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=[]\n",
    "for i in range(0, len(Mn2_C)):\n",
    "    labels.append(0)\n",
    "for i in range(0, len(Mn3_C)):\n",
    "    labels.append(1)\n",
    "for i in range(0, len(Mn4_C)):\n",
    "    labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Mn_All, labels, test_size=0.15, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_aug = []\n",
    "noise = np.copy(X_train)\n",
    "mu = np.mean(noise, axis=0)\n",
    "pca = PCA()\n",
    "noise_model = pca.fit(noise)\n",
    "nComp = 10\n",
    "Xhat = np.dot(pca.transform(noise)[:,:nComp], pca.components_[:nComp,:])\n",
    "noise_level = np.dot(pca.transform(noise)[:,nComp:], pca.components_[nComp:,:])\n",
    "Xhat += mu\n",
    "SNR = np.linspace(1,5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i  in range(len(SNR)):\n",
    "    noise_aug.append(SNR[i]*noise_level + Xhat)\n",
    "    j = 0\n",
    "    for spectra in noise_aug[i]:\n",
    "        noise_aug[i][j] = spectra/np.max(spectra)\n",
    "        j += 1\n",
    "X_train = np.array(noise_aug).reshape(50*2684,700)\n",
    "y_train = [item for i in range(50) for item in y_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train[:,100:600]\n",
    "X_test = X_test[:,100:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).astype('float32')\n",
    "X_train = X_train.reshape(X_train.shape + (1,))\n",
    "X_train -=  np.mean(X_train)\n",
    "X_train /= np.max(X_train)\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape + (1,))\n",
    "X_test -= np.mean(X_test)   \n",
    "X_test /= np.max(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 3 classes.\n",
      "Data mean-centered, normalized and hot-encoded.\n",
      "Total of 134200 training samples.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2NjYxCG28bexsbGJQ2zjb2NjYxOH/D9ZsZifymz1nwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Total of \"+str(num_classes)+\" classes.\")\n",
    "print(\"Data mean-centered, normalized and hot-encoded.\")\n",
    "print(\"Total of \"+str(len(X_train))+\" training samples.\")\n",
    "plt.plot(X_test[0])\n",
    "plt.plot(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 492, 2)            20        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 246, 2)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 246, 2)            8         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 2)            30        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 120, 2)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 120, 2)            8         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 114, 4)            60        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 57, 4)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 57, 4)             16        \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 53, 4)             84        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 26, 4)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 26, 4)             16        \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 24, 8)             104       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, 12, 8)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 8)             32        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 12, 3)             27        \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "loss (Activation)            (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 405\n",
      "Trainable params: 365\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "None\n",
      "CNN Model created.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "activation = 'relu'\n",
    "model.add(Convolution1D(2, 9, input_shape=(500,1), activation=activation))\n",
    "model.add(AveragePooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution1D(2, 7, activation=activation))\n",
    "model.add(AveragePooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution1D(4, 7, activation=activation))\n",
    "model.add(AveragePooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution1D(4, 5, activation=activation))\n",
    "model.add(AveragePooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Convolution1D(8, 3, activation=activation))\n",
    "model.add(AveragePooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.10))\n",
    "model.add(Convolution1D(3, 1))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "model.add(Activation('softmax', name='loss'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "print(\"CNN Model created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 512\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_file = \"highest_val_acc_weights_epoch{epoch:02d}-val_acc{val_acc:.3f}_cnn.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = ModelCheckpoint(best_model_file, monitor='val_acc', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134200 samples, validate on 474 samples\n",
      "Epoch 1/1000\n",
      "\r",
      "   512/134200 [..............................] - ETA: 46s - loss: 0.1186 - acc: 0.9590"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 33s 246us/step - loss: 0.1212 - acc: 0.9559 - val_loss: 0.0643 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.98101\n",
      "Epoch 2/1000\n",
      "134200/134200 [==============================] - 31s 229us/step - loss: 0.1187 - acc: 0.9568 - val_loss: 0.1064 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.98101\n",
      "Epoch 3/1000\n",
      "134200/134200 [==============================] - 31s 232us/step - loss: 0.1199 - acc: 0.9558 - val_loss: 0.0615 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98101\n",
      "Epoch 4/1000\n",
      "134200/134200 [==============================] - 39s 291us/step - loss: 0.1176 - acc: 0.9565 - val_loss: 0.0780 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.98101\n",
      "Epoch 5/1000\n",
      "134200/134200 [==============================] - 36s 267us/step - loss: 0.1162 - acc: 0.9572 - val_loss: 0.0628 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.98101\n",
      "Epoch 6/1000\n",
      "134200/134200 [==============================] - 35s 261us/step - loss: 0.1153 - acc: 0.9576 - val_loss: 0.0786 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98101\n",
      "Epoch 7/1000\n",
      "134200/134200 [==============================] - 40s 296us/step - loss: 0.1153 - acc: 0.9574 - val_loss: 0.0769 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98101\n",
      "Epoch 8/1000\n",
      "134200/134200 [==============================] - 35s 259us/step - loss: 0.1136 - acc: 0.9579 - val_loss: 0.0651 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98101\n",
      "Epoch 9/1000\n",
      "134200/134200 [==============================] - 33s 246us/step - loss: 0.1128 - acc: 0.9578 - val_loss: 0.0687 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98101\n",
      "Epoch 10/1000\n",
      "134200/134200 [==============================] - 35s 261us/step - loss: 0.1130 - acc: 0.9589 - val_loss: 0.0684 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.98101 to 0.98312, saving model to highest_val_acc_weights_epoch10-val_acc0.983_cnn.h5\n",
      "Epoch 11/1000\n",
      "134200/134200 [==============================] - 33s 243us/step - loss: 0.1128 - acc: 0.9587 - val_loss: 0.0616 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98312\n",
      "Epoch 12/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.1116 - acc: 0.9589 - val_loss: 0.0606 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98312\n",
      "Epoch 13/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.1110 - acc: 0.9594 - val_loss: 0.0675 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98312\n",
      "Epoch 14/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.1109 - acc: 0.9590 - val_loss: 0.0838 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98312\n",
      "Epoch 15/1000\n",
      "134200/134200 [==============================] - 31s 228us/step - loss: 0.1087 - acc: 0.9601 - val_loss: 0.0874 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98312\n",
      "Epoch 16/1000\n",
      "134200/134200 [==============================] - 32s 241us/step - loss: 0.1094 - acc: 0.9599 - val_loss: 0.1382 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98312\n",
      "Epoch 17/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.1086 - acc: 0.9602 - val_loss: 0.1890 - val_acc: 0.9177\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98312\n",
      "Epoch 18/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.1065 - acc: 0.9608 - val_loss: 0.1788 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.98312\n",
      "Epoch 19/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.1086 - acc: 0.9598 - val_loss: 0.0712 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.98312\n",
      "Epoch 20/1000\n",
      "134200/134200 [==============================] - 32s 235us/step - loss: 0.1070 - acc: 0.9599 - val_loss: 0.0599 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.98312\n",
      "Epoch 21/1000\n",
      "134200/134200 [==============================] - 32s 235us/step - loss: 0.1064 - acc: 0.9602 - val_loss: 0.1100 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.98312\n",
      "Epoch 22/1000\n",
      "134200/134200 [==============================] - 32s 240us/step - loss: 0.1063 - acc: 0.9613 - val_loss: 0.0879 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.98312\n",
      "Epoch 23/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.1066 - acc: 0.9608 - val_loss: 0.0527 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.98312\n",
      "Epoch 24/1000\n",
      "134200/134200 [==============================] - 30s 220us/step - loss: 0.1059 - acc: 0.9605 - val_loss: 0.0533 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.98312 to 0.98523, saving model to highest_val_acc_weights_epoch24-val_acc0.985_cnn.h5\n",
      "Epoch 25/1000\n",
      "134200/134200 [==============================] - 31s 228us/step - loss: 0.1052 - acc: 0.9611 - val_loss: 0.0580 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.98523\n",
      "Epoch 26/1000\n",
      "134200/134200 [==============================] - 30s 225us/step - loss: 0.1048 - acc: 0.9608 - val_loss: 0.0712 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.98523\n",
      "Epoch 27/1000\n",
      "134200/134200 [==============================] - 30s 225us/step - loss: 0.1042 - acc: 0.9611 - val_loss: 0.0552 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.98523\n",
      "Epoch 28/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.1051 - acc: 0.9611 - val_loss: 0.0594 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.98523\n",
      "Epoch 29/1000\n",
      "134200/134200 [==============================] - 30s 220us/step - loss: 0.1047 - acc: 0.9610 - val_loss: 0.0555 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.98523\n",
      "Epoch 30/1000\n",
      "134200/134200 [==============================] - 29s 220us/step - loss: 0.1034 - acc: 0.9615 - val_loss: 0.1222 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.98523\n",
      "Epoch 31/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.1034 - acc: 0.9615 - val_loss: 0.0628 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.98523\n",
      "Epoch 32/1000\n",
      "134200/134200 [==============================] - 32s 235us/step - loss: 0.1033 - acc: 0.9618 - val_loss: 0.0744 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.98523\n",
      "Epoch 33/1000\n",
      "134200/134200 [==============================] - 31s 232us/step - loss: 0.1021 - acc: 0.9620 - val_loss: 0.0662 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.98523\n",
      "Epoch 34/1000\n",
      "134200/134200 [==============================] - 32s 241us/step - loss: 0.1028 - acc: 0.9623 - val_loss: 0.0839 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.98523\n",
      "Epoch 35/1000\n",
      "134200/134200 [==============================] - 31s 229us/step - loss: 0.1037 - acc: 0.9619 - val_loss: 0.1231 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.98523\n",
      "Epoch 36/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.1011 - acc: 0.9621 - val_loss: 0.0495 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.98523\n",
      "Epoch 37/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.1007 - acc: 0.9627 - val_loss: 0.0607 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.98523\n",
      "Epoch 38/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.1015 - acc: 0.9626 - val_loss: 0.2799 - val_acc: 0.9262\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.98523\n",
      "Epoch 39/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.1018 - acc: 0.9619 - val_loss: 0.1081 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.98523\n",
      "Epoch 40/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.1010 - acc: 0.9623 - val_loss: 0.0716 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.98523\n",
      "Epoch 41/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0995 - acc: 0.9630 - val_loss: 0.0460 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.98523 to 0.98734, saving model to highest_val_acc_weights_epoch41-val_acc0.987_cnn.h5\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.1007 - acc: 0.9624 - val_loss: 0.0553 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.98734\n",
      "Epoch 43/1000\n",
      "134200/134200 [==============================] - 30s 225us/step - loss: 0.0998 - acc: 0.9629 - val_loss: 0.1055 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.98734\n",
      "Epoch 44/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0988 - acc: 0.9632 - val_loss: 0.0585 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.98734\n",
      "Epoch 45/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0983 - acc: 0.9635 - val_loss: 0.0673 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.98734\n",
      "Epoch 46/1000\n",
      "134200/134200 [==============================] - 33s 246us/step - loss: 0.0991 - acc: 0.9628 - val_loss: 0.0787 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.98734\n",
      "Epoch 47/1000\n",
      "134200/134200 [==============================] - 38s 284us/step - loss: 0.0988 - acc: 0.9629 - val_loss: 0.1050 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.98734\n",
      "Epoch 48/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0971 - acc: 0.9637 - val_loss: 0.0549 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.98734\n",
      "Epoch 49/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0982 - acc: 0.9637 - val_loss: 0.0683 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.98734\n",
      "Epoch 50/1000\n",
      "134200/134200 [==============================] - 31s 229us/step - loss: 0.0977 - acc: 0.9641 - val_loss: 0.0539 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.98734\n",
      "Epoch 51/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0972 - acc: 0.9645 - val_loss: 0.0528 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.98734\n",
      "Epoch 52/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0970 - acc: 0.9644 - val_loss: 0.0887 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.98734\n",
      "Epoch 53/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0980 - acc: 0.9634 - val_loss: 0.0574 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.98734\n",
      "Epoch 54/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0974 - acc: 0.9637 - val_loss: 0.0545 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.98734\n",
      "Epoch 55/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.0966 - acc: 0.9644 - val_loss: 0.0434 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.98734\n",
      "Epoch 56/1000\n",
      "134200/134200 [==============================] - 31s 230us/step - loss: 0.0965 - acc: 0.9649 - val_loss: 0.0486 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.98734\n",
      "Epoch 57/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.0973 - acc: 0.9639 - val_loss: 0.0523 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.98734\n",
      "Epoch 58/1000\n",
      "134200/134200 [==============================] - 1901s 14ms/step - loss: 0.0957 - acc: 0.9644 - val_loss: 0.0693 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.98734\n",
      "Epoch 59/1000\n",
      "134200/134200 [==============================] - 42s 310us/step - loss: 0.0949 - acc: 0.9649 - val_loss: 0.0736 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.98734\n",
      "Epoch 60/1000\n",
      "134200/134200 [==============================] - 38s 281us/step - loss: 0.0958 - acc: 0.9650 - val_loss: 0.0634 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.98734\n",
      "Epoch 61/1000\n",
      "134200/134200 [==============================] - 33s 245us/step - loss: 0.0950 - acc: 0.9648 - val_loss: 0.0556 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.98734\n",
      "Epoch 62/1000\n",
      "134200/134200 [==============================] - 31s 234us/step - loss: 0.0962 - acc: 0.9645 - val_loss: 0.0572 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.98734\n",
      "Epoch 63/1000\n",
      "134200/134200 [==============================] - 32s 240us/step - loss: 0.0950 - acc: 0.9652 - val_loss: 0.0519 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.98734\n",
      "Epoch 64/1000\n",
      "134200/134200 [==============================] - 39s 290us/step - loss: 0.0951 - acc: 0.9645 - val_loss: 0.0834 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.98734\n",
      "Epoch 65/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0950 - acc: 0.9647 - val_loss: 0.0662 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.98734\n",
      "Epoch 66/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0953 - acc: 0.9651 - val_loss: 0.0696 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.98734\n",
      "Epoch 67/1000\n",
      "134200/134200 [==============================] - 30s 220us/step - loss: 0.0944 - acc: 0.9656 - val_loss: 0.0783 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.98734\n",
      "Epoch 68/1000\n",
      "134200/134200 [==============================] - 32s 239us/step - loss: 0.0952 - acc: 0.9654 - val_loss: 0.0799 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.98734\n",
      "Epoch 69/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0949 - acc: 0.9649 - val_loss: 0.0583 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.98734\n",
      "Epoch 70/1000\n",
      "134200/134200 [==============================] - 35s 260us/step - loss: 0.0961 - acc: 0.9646 - val_loss: 0.0598 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.98734\n",
      "Epoch 71/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0931 - acc: 0.9657 - val_loss: 0.0543 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.98734\n",
      "Epoch 72/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0953 - acc: 0.9648 - val_loss: 0.0888 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.98734\n",
      "Epoch 73/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0961 - acc: 0.9650 - val_loss: 0.0655 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.98734\n",
      "Epoch 74/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0936 - acc: 0.9656 - val_loss: 0.0608 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.98734\n",
      "Epoch 75/1000\n",
      "134200/134200 [==============================] - 31s 233us/step - loss: 0.0928 - acc: 0.9661 - val_loss: 0.0485 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.98734\n",
      "Epoch 76/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0933 - acc: 0.9659 - val_loss: 0.0568 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.98734\n",
      "Epoch 77/1000\n",
      "134200/134200 [==============================] - 35s 258us/step - loss: 0.0937 - acc: 0.9656 - val_loss: 0.0838 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.98734\n",
      "Epoch 78/1000\n",
      "134200/134200 [==============================] - 41s 307us/step - loss: 0.0927 - acc: 0.9665 - val_loss: 0.0542 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.98734\n",
      "Epoch 79/1000\n",
      "134200/134200 [==============================] - 33s 243us/step - loss: 0.0930 - acc: 0.9656 - val_loss: 0.0666 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.98734\n",
      "Epoch 80/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0931 - acc: 0.9661 - val_loss: 0.1239 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.98734\n",
      "Epoch 81/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0936 - acc: 0.9655 - val_loss: 0.0513 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.98734\n",
      "Epoch 82/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.0923 - acc: 0.9661 - val_loss: 0.0561 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.98734\n",
      "Epoch 83/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0917 - acc: 0.9664 - val_loss: 0.0754 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.98734\n",
      "Epoch 84/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 27s 200us/step - loss: 0.0928 - acc: 0.9661 - val_loss: 0.6661 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.98734\n",
      "Epoch 85/1000\n",
      "134200/134200 [==============================] - 27s 202us/step - loss: 0.0918 - acc: 0.9665 - val_loss: 0.4519 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.98734\n",
      "Epoch 86/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0927 - acc: 0.9668 - val_loss: 0.0718 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.98734\n",
      "Epoch 87/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0925 - acc: 0.9661 - val_loss: 0.0693 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.98734\n",
      "Epoch 88/1000\n",
      "134200/134200 [==============================] - 31s 228us/step - loss: 0.0914 - acc: 0.9664 - val_loss: 0.0466 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.98734\n",
      "Epoch 89/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0905 - acc: 0.9669 - val_loss: 0.2423 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.98734\n",
      "Epoch 90/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0927 - acc: 0.9661 - val_loss: 0.0707 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.98734\n",
      "Epoch 91/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0913 - acc: 0.9662 - val_loss: 0.0714 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.98734\n",
      "Epoch 92/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0910 - acc: 0.9663 - val_loss: 0.3046 - val_acc: 0.8903\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.98734\n",
      "Epoch 93/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0922 - acc: 0.9663 - val_loss: 0.0638 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.98734\n",
      "Epoch 94/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0904 - acc: 0.9675 - val_loss: 0.0600 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.98734\n",
      "Epoch 95/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0921 - acc: 0.9667 - val_loss: 0.3819 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.98734\n",
      "Epoch 96/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0901 - acc: 0.9671 - val_loss: 0.0583 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.98734\n",
      "Epoch 97/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0903 - acc: 0.9677 - val_loss: 0.0752 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.98734\n",
      "Epoch 98/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0904 - acc: 0.9674 - val_loss: 0.1516 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.98734\n",
      "Epoch 99/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.0906 - acc: 0.9669 - val_loss: 0.0651 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.98734\n",
      "Epoch 100/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0894 - acc: 0.9677 - val_loss: 0.0924 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.98734\n",
      "Epoch 101/1000\n",
      "134200/134200 [==============================] - 31s 228us/step - loss: 0.0896 - acc: 0.9674 - val_loss: 0.0758 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.98734\n",
      "Epoch 102/1000\n",
      "134200/134200 [==============================] - 30s 220us/step - loss: 0.0898 - acc: 0.9673 - val_loss: 0.0693 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.98734\n",
      "Epoch 103/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0895 - acc: 0.9675 - val_loss: 0.0574 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.98734\n",
      "Epoch 104/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0903 - acc: 0.9673 - val_loss: 0.0555 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.98734\n",
      "Epoch 105/1000\n",
      "134200/134200 [==============================] - 42s 312us/step - loss: 0.0892 - acc: 0.9674 - val_loss: 0.0758 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.98734\n",
      "Epoch 106/1000\n",
      "134200/134200 [==============================] - 35s 259us/step - loss: 0.0892 - acc: 0.9676 - val_loss: 0.0843 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.98734\n",
      "Epoch 107/1000\n",
      "134200/134200 [==============================] - 35s 258us/step - loss: 0.0898 - acc: 0.9673 - val_loss: 0.0579 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.98734\n",
      "Epoch 108/1000\n",
      "134200/134200 [==============================] - 31s 230us/step - loss: 0.0877 - acc: 0.9679 - val_loss: 0.0524 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.98734\n",
      "Epoch 109/1000\n",
      "134200/134200 [==============================] - 34s 257us/step - loss: 0.0874 - acc: 0.9684 - val_loss: 0.0775 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.98734\n",
      "Epoch 110/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0895 - acc: 0.9675 - val_loss: 0.1527 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.98734\n",
      "Epoch 111/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0884 - acc: 0.9681 - val_loss: 0.0988 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.98734\n",
      "Epoch 112/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0893 - acc: 0.9674 - val_loss: 0.0535 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.98734\n",
      "Epoch 113/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0884 - acc: 0.9676 - val_loss: 0.0585 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.98734\n",
      "Epoch 114/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0882 - acc: 0.9678 - val_loss: 0.0947 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.98734\n",
      "Epoch 115/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0884 - acc: 0.9678 - val_loss: 0.0873 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.98734\n",
      "Epoch 116/1000\n",
      "134200/134200 [==============================] - 34s 251us/step - loss: 0.0880 - acc: 0.9678 - val_loss: 0.0549 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.98734\n",
      "Epoch 117/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0895 - acc: 0.9670 - val_loss: 0.0592 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.98734\n",
      "Epoch 118/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0882 - acc: 0.9679 - val_loss: 0.0613 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.98734\n",
      "Epoch 119/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0876 - acc: 0.9680 - val_loss: 0.0621 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.98734\n",
      "Epoch 120/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0880 - acc: 0.9678 - val_loss: 0.0502 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.98734\n",
      "Epoch 121/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0888 - acc: 0.9680 - val_loss: 0.2426 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.98734\n",
      "Epoch 122/1000\n",
      "134200/134200 [==============================] - 38s 281us/step - loss: 0.0899 - acc: 0.9672 - val_loss: 0.0559 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.98734\n",
      "Epoch 123/1000\n",
      "134200/134200 [==============================] - 30s 226us/step - loss: 0.0885 - acc: 0.9675 - val_loss: 0.0612 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.98734\n",
      "Epoch 124/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0883 - acc: 0.9674 - val_loss: 0.0533 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.98734\n",
      "Epoch 125/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0875 - acc: 0.9682 - val_loss: 0.0689 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.98734\n",
      "Epoch 126/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0868 - acc: 0.9680 - val_loss: 0.0622 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.98734\n",
      "Epoch 127/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0886 - acc: 0.9677 - val_loss: 0.0671 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.98734\n",
      "Epoch 128/1000\n",
      "134200/134200 [==============================] - 29s 220us/step - loss: 0.0889 - acc: 0.9676 - val_loss: 0.1295 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.98734\n",
      "Epoch 129/1000\n",
      "134200/134200 [==============================] - 30s 227us/step - loss: 0.0882 - acc: 0.9677 - val_loss: 0.0468 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.98734\n",
      "Epoch 130/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0856 - acc: 0.9685 - val_loss: 0.0658 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.98734\n",
      "Epoch 131/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0865 - acc: 0.9682 - val_loss: 0.0612 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.98734\n",
      "Epoch 132/1000\n",
      "134200/134200 [==============================] - 259s 2ms/step - loss: 0.0860 - acc: 0.9688 - val_loss: 0.0626 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.98734\n",
      "Epoch 133/1000\n",
      "134200/134200 [==============================] - 35s 259us/step - loss: 0.0880 - acc: 0.9682 - val_loss: 0.1233 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.98734\n",
      "Epoch 134/1000\n",
      "134200/134200 [==============================] - 30s 226us/step - loss: 0.0869 - acc: 0.9687 - val_loss: 0.0652 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.98734\n",
      "Epoch 135/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.0871 - acc: 0.9681 - val_loss: 0.0669 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.98734\n",
      "Epoch 136/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0865 - acc: 0.9683 - val_loss: 0.0543 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.98734\n",
      "Epoch 137/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0865 - acc: 0.9683 - val_loss: 0.1229 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.98734\n",
      "Epoch 138/1000\n",
      "134200/134200 [==============================] - 231s 2ms/step - loss: 0.0866 - acc: 0.9681 - val_loss: 0.0532 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.98734\n",
      "Epoch 139/1000\n",
      "134200/134200 [==============================] - 32s 242us/step - loss: 0.0863 - acc: 0.9682 - val_loss: 0.0629 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.98734\n",
      "Epoch 140/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0850 - acc: 0.9687 - val_loss: 0.0587 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.98734\n",
      "Epoch 141/1000\n",
      "134200/134200 [==============================] - 32s 237us/step - loss: 0.0871 - acc: 0.9678 - val_loss: 0.0532 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.98734\n",
      "Epoch 142/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0855 - acc: 0.9690 - val_loss: 0.0781 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.98734\n",
      "Epoch 143/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0868 - acc: 0.9679 - val_loss: 0.0496 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.98734\n",
      "Epoch 144/1000\n",
      "134200/134200 [==============================] - 27s 202us/step - loss: 0.0866 - acc: 0.9684 - val_loss: 0.0608 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.98734\n",
      "Epoch 145/1000\n",
      "134200/134200 [==============================] - 27s 202us/step - loss: 0.0862 - acc: 0.9682 - val_loss: 0.0762 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.98734\n",
      "Epoch 146/1000\n",
      "134200/134200 [==============================] - 27s 202us/step - loss: 0.0868 - acc: 0.9679 - val_loss: 0.0553 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.98734\n",
      "Epoch 147/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0860 - acc: 0.9686 - val_loss: 0.0799 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.98734\n",
      "Epoch 148/1000\n",
      "134200/134200 [==============================] - 30s 225us/step - loss: 0.0862 - acc: 0.9682 - val_loss: 0.0524 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.98734\n",
      "Epoch 149/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0852 - acc: 0.9682 - val_loss: 0.0783 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.98734\n",
      "Epoch 150/1000\n",
      "134200/134200 [==============================] - 34s 250us/step - loss: 0.0860 - acc: 0.9683 - val_loss: 0.0550 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.98734\n",
      "Epoch 151/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0854 - acc: 0.9686 - val_loss: 0.0664 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.98734\n",
      "Epoch 152/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0866 - acc: 0.9683 - val_loss: 0.2979 - val_acc: 0.8903\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.98734\n",
      "Epoch 153/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0863 - acc: 0.9687 - val_loss: 0.0571 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.98734\n",
      "Epoch 154/1000\n",
      "134200/134200 [==============================] - 27s 202us/step - loss: 0.0850 - acc: 0.9687 - val_loss: 0.0991 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.98734\n",
      "Epoch 155/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0865 - acc: 0.9682 - val_loss: 0.0757 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.98734\n",
      "Epoch 156/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0859 - acc: 0.9683 - val_loss: 0.0599 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.98734\n",
      "Epoch 157/1000\n",
      "134200/134200 [==============================] - 27s 202us/step - loss: 0.0845 - acc: 0.9685 - val_loss: 0.0665 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.98734\n",
      "Epoch 158/1000\n",
      "134200/134200 [==============================] - 28s 205us/step - loss: 0.0851 - acc: 0.9686 - val_loss: 0.0613 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.98734\n",
      "Epoch 159/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0850 - acc: 0.9688 - val_loss: 0.0802 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.98734\n",
      "Epoch 160/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0854 - acc: 0.9684 - val_loss: 0.0748 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.98734\n",
      "Epoch 161/1000\n",
      "134200/134200 [==============================] - 34s 252us/step - loss: 0.0858 - acc: 0.9679 - val_loss: 0.0900 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.98734\n",
      "Epoch 162/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0855 - acc: 0.9683 - val_loss: 0.0581 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.98734\n",
      "Epoch 163/1000\n",
      "134200/134200 [==============================] - 27s 202us/step - loss: 0.0853 - acc: 0.9685 - val_loss: 0.0513 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.98734\n",
      "Epoch 164/1000\n",
      "134200/134200 [==============================] - 28s 205us/step - loss: 0.0844 - acc: 0.9687 - val_loss: 0.0611 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.98734\n",
      "Epoch 165/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0848 - acc: 0.9691 - val_loss: 0.0903 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.98734\n",
      "Epoch 166/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0863 - acc: 0.9685 - val_loss: 0.0933 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.98734\n",
      "Epoch 167/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0850 - acc: 0.9688 - val_loss: 0.0533 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.98734\n",
      "Epoch 168/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0859 - acc: 0.9685 - val_loss: 0.0653 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.98734\n",
      "Epoch 169/1000\n",
      "134200/134200 [==============================] - 28s 205us/step - loss: 0.0857 - acc: 0.9680 - val_loss: 0.0776 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.98734\n",
      "Epoch 170/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0848 - acc: 0.9686 - val_loss: 0.0740 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.98734\n",
      "Epoch 171/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0858 - acc: 0.9685 - val_loss: 0.0763 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.98734\n",
      "Epoch 172/1000\n",
      "134200/134200 [==============================] - 30s 225us/step - loss: 0.0852 - acc: 0.9683 - val_loss: 0.0728 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.98734\n",
      "Epoch 173/1000\n",
      "134200/134200 [==============================] - 31s 228us/step - loss: 0.0849 - acc: 0.9687 - val_loss: 0.0625 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.98734\n",
      "Epoch 174/1000\n",
      "134200/134200 [==============================] - 28s 205us/step - loss: 0.0848 - acc: 0.9687 - val_loss: 0.1270 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.98734\n",
      "Epoch 175/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0846 - acc: 0.9686 - val_loss: 0.0562 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.98734\n",
      "Epoch 176/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0847 - acc: 0.9688 - val_loss: 0.1582 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.98734\n",
      "Epoch 177/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0843 - acc: 0.9693 - val_loss: 0.0634 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.98734\n",
      "Epoch 178/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0852 - acc: 0.9681 - val_loss: 0.0915 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.98734\n",
      "Epoch 179/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0845 - acc: 0.9688 - val_loss: 0.0517 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.98734\n",
      "Epoch 180/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0840 - acc: 0.9691 - val_loss: 0.1021 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.98734\n",
      "Epoch 181/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0834 - acc: 0.9691 - val_loss: 0.0725 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.98734\n",
      "Epoch 182/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0849 - acc: 0.9686 - val_loss: 0.0480 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.98734\n",
      "Epoch 183/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0843 - acc: 0.9686 - val_loss: 0.0591 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.98734\n",
      "Epoch 184/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0853 - acc: 0.9683 - val_loss: 0.1019 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.98734\n",
      "Epoch 185/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0855 - acc: 0.9677 - val_loss: 0.0622 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.98734\n",
      "Epoch 186/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.0839 - acc: 0.9689 - val_loss: 0.0648 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.98734\n",
      "Epoch 187/1000\n",
      "134200/134200 [==============================] - 33s 242us/step - loss: 0.0831 - acc: 0.9698 - val_loss: 0.1416 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.98734\n",
      "Epoch 188/1000\n",
      "134200/134200 [==============================] - 34s 255us/step - loss: 0.0839 - acc: 0.9690 - val_loss: 0.0656 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.98734\n",
      "Epoch 189/1000\n",
      "134200/134200 [==============================] - 27s 205us/step - loss: 0.0839 - acc: 0.9689 - val_loss: 0.0602 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.98734\n",
      "Epoch 190/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0844 - acc: 0.9686 - val_loss: 0.0666 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.98734\n",
      "Epoch 191/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0831 - acc: 0.9692 - val_loss: 0.0576 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.98734\n",
      "Epoch 192/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0837 - acc: 0.9689 - val_loss: 0.0642 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.98734\n",
      "Epoch 193/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0819 - acc: 0.9698 - val_loss: 0.0707 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.98734\n",
      "Epoch 194/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0851 - acc: 0.9685 - val_loss: 0.0767 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.98734\n",
      "Epoch 195/1000\n",
      "134200/134200 [==============================] - 34s 252us/step - loss: 0.0835 - acc: 0.9691 - val_loss: 0.2315 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.98734\n",
      "Epoch 196/1000\n",
      "134200/134200 [==============================] - 34s 251us/step - loss: 0.0837 - acc: 0.9692 - val_loss: 0.0605 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.98734\n",
      "Epoch 197/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0823 - acc: 0.9695 - val_loss: 0.0597 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.98734\n",
      "Epoch 198/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0835 - acc: 0.9692 - val_loss: 0.0554 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.98734\n",
      "Epoch 199/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0834 - acc: 0.9690 - val_loss: 0.0554 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.98734\n",
      "Epoch 200/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0821 - acc: 0.9701 - val_loss: 0.0570 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.98734\n",
      "Epoch 201/1000\n",
      "134200/134200 [==============================] - 26s 197us/step - loss: 0.0820 - acc: 0.9695 - val_loss: 0.0537 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.98734\n",
      "Epoch 202/1000\n",
      "134200/134200 [==============================] - 27s 199us/step - loss: 0.0834 - acc: 0.9688 - val_loss: 0.0585 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.98734\n",
      "Epoch 203/1000\n",
      "134200/134200 [==============================] - 27s 198us/step - loss: 0.0832 - acc: 0.9696 - val_loss: 0.0628 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.98734\n",
      "Epoch 204/1000\n",
      "134200/134200 [==============================] - 27s 200us/step - loss: 0.0840 - acc: 0.9689 - val_loss: 0.0530 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.98734\n",
      "Epoch 205/1000\n",
      "134200/134200 [==============================] - 27s 198us/step - loss: 0.0824 - acc: 0.9695 - val_loss: 0.0621 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.98734\n",
      "Epoch 206/1000\n",
      "134200/134200 [==============================] - 27s 202us/step - loss: 0.0824 - acc: 0.9697 - val_loss: 0.0639 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.98734\n",
      "Epoch 207/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0833 - acc: 0.9690 - val_loss: 0.0574 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.98734\n",
      "Epoch 208/1000\n",
      "134200/134200 [==============================] - 32s 237us/step - loss: 0.0819 - acc: 0.9702 - val_loss: 0.3075 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.98734\n",
      "Epoch 209/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0826 - acc: 0.9695 - val_loss: 0.0613 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.98734\n",
      "Epoch 210/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0833 - acc: 0.9687 - val_loss: 0.0572 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.98734\n",
      "Epoch 211/1000\n",
      "134200/134200 [==============================] - 30s 225us/step - loss: 0.0821 - acc: 0.9697 - val_loss: 0.0640 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.98734\n",
      "Epoch 212/1000\n",
      "134200/134200 [==============================] - 31s 227us/step - loss: 0.0814 - acc: 0.9698 - val_loss: 0.1093 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.98734\n",
      "Epoch 213/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0829 - acc: 0.9698 - val_loss: 0.0653 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.98734\n",
      "Epoch 214/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0831 - acc: 0.9692 - val_loss: 0.0515 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.98734\n",
      "Epoch 215/1000\n",
      "134200/134200 [==============================] - 31s 230us/step - loss: 0.0818 - acc: 0.9695 - val_loss: 0.0540 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.98734\n",
      "Epoch 216/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0823 - acc: 0.9697 - val_loss: 0.0680 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.98734\n",
      "Epoch 217/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0831 - acc: 0.9691 - val_loss: 0.0670 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.98734\n",
      "Epoch 218/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0824 - acc: 0.9694 - val_loss: 0.0618 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.98734\n",
      "Epoch 219/1000\n",
      "134200/134200 [==============================] - 30s 226us/step - loss: 0.0817 - acc: 0.9702 - val_loss: 0.0544 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.98734\n",
      "Epoch 220/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0819 - acc: 0.9697 - val_loss: 0.0676 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.98734\n",
      "Epoch 221/1000\n",
      "134200/134200 [==============================] - 30s 227us/step - loss: 0.0840 - acc: 0.9689 - val_loss: 0.0579 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.98734\n",
      "Epoch 222/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0821 - acc: 0.9694 - val_loss: 0.0546 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.98734\n",
      "Epoch 223/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0834 - acc: 0.9692 - val_loss: 0.0756 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.98734\n",
      "Epoch 224/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0832 - acc: 0.9693 - val_loss: 0.0713 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.98734\n",
      "Epoch 225/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0825 - acc: 0.9692 - val_loss: 0.0689 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.98734\n",
      "Epoch 226/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0831 - acc: 0.9691 - val_loss: 0.0581 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.98734\n",
      "Epoch 227/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0822 - acc: 0.9692 - val_loss: 0.0556 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.98734\n",
      "Epoch 228/1000\n",
      "134200/134200 [==============================] - 33s 245us/step - loss: 0.0809 - acc: 0.9706 - val_loss: 0.0892 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.98734\n",
      "Epoch 229/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0825 - acc: 0.9696 - val_loss: 0.0631 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.98734\n",
      "Epoch 230/1000\n",
      "134200/134200 [==============================] - 30s 227us/step - loss: 0.0819 - acc: 0.9692 - val_loss: 0.0939 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.98734\n",
      "Epoch 231/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0822 - acc: 0.9699 - val_loss: 0.1258 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.98734\n",
      "Epoch 232/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0825 - acc: 0.9694 - val_loss: 0.0671 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.98734\n",
      "Epoch 233/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0818 - acc: 0.9698 - val_loss: 0.0960 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.98734\n",
      "Epoch 234/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0822 - acc: 0.9696 - val_loss: 0.0808 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.98734\n",
      "Epoch 235/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0815 - acc: 0.9699 - val_loss: 0.0809 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.98734\n",
      "Epoch 236/1000\n",
      "134200/134200 [==============================] - 33s 248us/step - loss: 0.0830 - acc: 0.9692 - val_loss: 0.1558 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.98734\n",
      "Epoch 237/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0826 - acc: 0.9696 - val_loss: 0.0627 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.98734\n",
      "Epoch 238/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0822 - acc: 0.9697 - val_loss: 0.0694 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.98734\n",
      "Epoch 239/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0817 - acc: 0.9699 - val_loss: 0.0667 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.98734\n",
      "Epoch 240/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0816 - acc: 0.9696 - val_loss: 0.0599 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.98734\n",
      "Epoch 241/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0815 - acc: 0.9700 - val_loss: 0.0766 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.98734\n",
      "Epoch 242/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0826 - acc: 0.9690 - val_loss: 0.0712 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.98734\n",
      "Epoch 243/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0840 - acc: 0.9687 - val_loss: 0.0662 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.98734\n",
      "Epoch 244/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0832 - acc: 0.9692 - val_loss: 0.0662 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.98734\n",
      "Epoch 245/1000\n",
      "134200/134200 [==============================] - 33s 242us/step - loss: 0.0825 - acc: 0.9696 - val_loss: 0.0899 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.98734\n",
      "Epoch 246/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0813 - acc: 0.9699 - val_loss: 0.2426 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.98734\n",
      "Epoch 247/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0825 - acc: 0.9700 - val_loss: 0.0700 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.98734\n",
      "Epoch 248/1000\n",
      "134200/134200 [==============================] - 33s 244us/step - loss: 0.0816 - acc: 0.9694 - val_loss: 0.1456 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.98734\n",
      "Epoch 249/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0824 - acc: 0.9697 - val_loss: 0.0653 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.98734\n",
      "Epoch 250/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0819 - acc: 0.9694 - val_loss: 0.0699 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.98734\n",
      "Epoch 251/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0818 - acc: 0.9700 - val_loss: 0.0619 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.98734\n",
      "Epoch 252/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 31s 233us/step - loss: 0.0831 - acc: 0.9696 - val_loss: 0.0717 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.98734\n",
      "Epoch 253/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0805 - acc: 0.9703 - val_loss: 0.0571 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.98734\n",
      "Epoch 254/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0813 - acc: 0.9703 - val_loss: 0.0649 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.98734\n",
      "Epoch 255/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0815 - acc: 0.9699 - val_loss: 0.0981 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.98734\n",
      "Epoch 256/1000\n",
      "134200/134200 [==============================] - 46s 342us/step - loss: 0.0817 - acc: 0.9696 - val_loss: 0.0556 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.98734\n",
      "Epoch 257/1000\n",
      "134200/134200 [==============================] - 36s 270us/step - loss: 0.0827 - acc: 0.9696 - val_loss: 0.0622 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.98734\n",
      "Epoch 258/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0805 - acc: 0.9701 - val_loss: 0.1368 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.98734\n",
      "Epoch 259/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0809 - acc: 0.9699 - val_loss: 0.0513 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.98734\n",
      "Epoch 260/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0827 - acc: 0.9696 - val_loss: 0.1091 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.98734\n",
      "Epoch 261/1000\n",
      "134200/134200 [==============================] - 764s 6ms/step - loss: 0.0822 - acc: 0.9699 - val_loss: 0.0960 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.98734\n",
      "Epoch 262/1000\n",
      "134200/134200 [==============================] - 38s 282us/step - loss: 0.0814 - acc: 0.9701 - val_loss: 0.0735 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.98734\n",
      "Epoch 263/1000\n",
      "134200/134200 [==============================] - 31s 232us/step - loss: 0.0815 - acc: 0.9701 - val_loss: 0.0574 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.98734\n",
      "Epoch 264/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0815 - acc: 0.9699 - val_loss: 0.0578 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.98734\n",
      "Epoch 265/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0821 - acc: 0.9701 - val_loss: 0.1403 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.98734\n",
      "Epoch 266/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0818 - acc: 0.9700 - val_loss: 0.0615 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.98734\n",
      "Epoch 267/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0810 - acc: 0.9700 - val_loss: 0.0575 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.98734\n",
      "Epoch 268/1000\n",
      "134200/134200 [==============================] - 35s 263us/step - loss: 0.0836 - acc: 0.9702 - val_loss: 0.0717 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.98734\n",
      "Epoch 269/1000\n",
      "134200/134200 [==============================] - 43s 318us/step - loss: 0.0817 - acc: 0.9705 - val_loss: 0.0752 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.98734\n",
      "Epoch 270/1000\n",
      "134200/134200 [==============================] - 34s 254us/step - loss: 0.0840 - acc: 0.9685 - val_loss: 0.0623 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.98734\n",
      "Epoch 271/1000\n",
      "134200/134200 [==============================] - 15039s 112ms/step - loss: 0.0818 - acc: 0.9700 - val_loss: 0.0581 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.98734\n",
      "Epoch 272/1000\n",
      "134200/134200 [==============================] - 56s 415us/step - loss: 0.0815 - acc: 0.9696 - val_loss: 0.0592 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.98734\n",
      "Epoch 273/1000\n",
      "134200/134200 [==============================] - 51s 383us/step - loss: 0.0812 - acc: 0.9699 - val_loss: 0.0602 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.98734\n",
      "Epoch 274/1000\n",
      "134200/134200 [==============================] - 38s 284us/step - loss: 0.0824 - acc: 0.9697 - val_loss: 0.0634 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.98734\n",
      "Epoch 275/1000\n",
      "134200/134200 [==============================] - 54s 399us/step - loss: 0.0812 - acc: 0.9700 - val_loss: 0.0623 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.98734\n",
      "Epoch 276/1000\n",
      "134200/134200 [==============================] - 52s 386us/step - loss: 0.0835 - acc: 0.9692 - val_loss: 0.0808 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.98734\n",
      "Epoch 277/1000\n",
      "134200/134200 [==============================] - 48s 355us/step - loss: 0.0810 - acc: 0.9700 - val_loss: 0.7103 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.98734\n",
      "Epoch 278/1000\n",
      "134200/134200 [==============================] - 43s 322us/step - loss: 0.0818 - acc: 0.9691 - val_loss: 0.0575 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.98734\n",
      "Epoch 279/1000\n",
      "134200/134200 [==============================] - 42s 315us/step - loss: 0.0826 - acc: 0.9696 - val_loss: 0.0946 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.98734\n",
      "Epoch 280/1000\n",
      "134200/134200 [==============================] - 38s 280us/step - loss: 0.0820 - acc: 0.9698 - val_loss: 0.0647 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.98734\n",
      "Epoch 281/1000\n",
      "134200/134200 [==============================] - 43s 317us/step - loss: 0.0821 - acc: 0.9696 - val_loss: 0.4633 - val_acc: 0.8439\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.98734\n",
      "Epoch 282/1000\n",
      "134200/134200 [==============================] - 39s 293us/step - loss: 0.0813 - acc: 0.9700 - val_loss: 0.0678 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.98734\n",
      "Epoch 283/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0821 - acc: 0.9700 - val_loss: 0.0569 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.98734\n",
      "Epoch 284/1000\n",
      "134200/134200 [==============================] - 48s 361us/step - loss: 0.0806 - acc: 0.9704 - val_loss: 0.0510 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.98734\n",
      "Epoch 285/1000\n",
      "134200/134200 [==============================] - 76s 568us/step - loss: 0.0824 - acc: 0.9699 - val_loss: 0.0930 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.98734\n",
      "Epoch 286/1000\n",
      "134200/134200 [==============================] - 40s 299us/step - loss: 0.0828 - acc: 0.9693 - val_loss: 0.1218 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.98734\n",
      "Epoch 287/1000\n",
      "134200/134200 [==============================] - 34s 251us/step - loss: 0.0819 - acc: 0.9695 - val_loss: 0.0896 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.98734\n",
      "Epoch 288/1000\n",
      "134200/134200 [==============================] - 34s 251us/step - loss: 0.0826 - acc: 0.9692 - val_loss: 0.0543 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.98734\n",
      "Epoch 289/1000\n",
      "134200/134200 [==============================] - 34s 253us/step - loss: 0.0824 - acc: 0.9694 - val_loss: 0.0853 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.98734\n",
      "Epoch 290/1000\n",
      "134200/134200 [==============================] - 35s 259us/step - loss: 0.0817 - acc: 0.9696 - val_loss: 0.0619 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.98734\n",
      "Epoch 291/1000\n",
      "134200/134200 [==============================] - 32s 241us/step - loss: 0.0816 - acc: 0.9700 - val_loss: 0.0827 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.98734\n",
      "Epoch 292/1000\n",
      "134200/134200 [==============================] - 34s 255us/step - loss: 0.0819 - acc: 0.9698 - val_loss: 0.0598 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.98734\n",
      "Epoch 293/1000\n",
      "134200/134200 [==============================] - 35s 259us/step - loss: 0.0824 - acc: 0.9695 - val_loss: 0.0760 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.98734\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 32s 241us/step - loss: 0.0814 - acc: 0.9699 - val_loss: 0.0688 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.98734\n",
      "Epoch 295/1000\n",
      "134200/134200 [==============================] - 31s 232us/step - loss: 0.0805 - acc: 0.9702 - val_loss: 0.0557 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.98734\n",
      "Epoch 296/1000\n",
      "134200/134200 [==============================] - 33s 245us/step - loss: 0.0820 - acc: 0.9699 - val_loss: 0.0544 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.98734\n",
      "Epoch 297/1000\n",
      "134200/134200 [==============================] - 34s 253us/step - loss: 0.0814 - acc: 0.9698 - val_loss: 0.0596 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.98734\n",
      "Epoch 298/1000\n",
      "134200/134200 [==============================] - 31s 229us/step - loss: 0.0820 - acc: 0.9697 - val_loss: 0.0909 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.98734\n",
      "Epoch 299/1000\n",
      "134200/134200 [==============================] - 32s 236us/step - loss: 0.0833 - acc: 0.9691 - val_loss: 0.0587 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.98734\n",
      "Epoch 300/1000\n",
      "134200/134200 [==============================] - 35s 260us/step - loss: 0.0812 - acc: 0.9698 - val_loss: 0.0561 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.98734\n",
      "Epoch 301/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0818 - acc: 0.9698 - val_loss: 0.0794 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00301: val_acc did not improve from 0.98734\n",
      "Epoch 302/1000\n",
      "134200/134200 [==============================] - 31s 228us/step - loss: 0.0815 - acc: 0.9700 - val_loss: 0.0601 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00302: val_acc did not improve from 0.98734\n",
      "Epoch 303/1000\n",
      "134200/134200 [==============================] - 34s 251us/step - loss: 0.0821 - acc: 0.9699 - val_loss: 0.0589 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00303: val_acc did not improve from 0.98734\n",
      "Epoch 304/1000\n",
      "134200/134200 [==============================] - 32s 236us/step - loss: 0.0813 - acc: 0.9701 - val_loss: 0.0658 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00304: val_acc did not improve from 0.98734\n",
      "Epoch 305/1000\n",
      "134200/134200 [==============================] - 32s 236us/step - loss: 0.0812 - acc: 0.9699 - val_loss: 0.0662 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00305: val_acc did not improve from 0.98734\n",
      "Epoch 306/1000\n",
      "134200/134200 [==============================] - 31s 230us/step - loss: 0.0814 - acc: 0.9702 - val_loss: 0.0674 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00306: val_acc did not improve from 0.98734\n",
      "Epoch 307/1000\n",
      "134200/134200 [==============================] - 32s 235us/step - loss: 0.0821 - acc: 0.9694 - val_loss: 0.0641 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00307: val_acc did not improve from 0.98734\n",
      "Epoch 308/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0810 - acc: 0.9701 - val_loss: 0.0715 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00308: val_acc did not improve from 0.98734\n",
      "Epoch 309/1000\n",
      "134200/134200 [==============================] - 33s 248us/step - loss: 0.0828 - acc: 0.9695 - val_loss: 0.0593 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00309: val_acc did not improve from 0.98734\n",
      "Epoch 310/1000\n",
      "134200/134200 [==============================] - 36s 267us/step - loss: 0.0808 - acc: 0.9702 - val_loss: 0.0702 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00310: val_acc did not improve from 0.98734\n",
      "Epoch 311/1000\n",
      "134200/134200 [==============================] - 32s 237us/step - loss: 0.0822 - acc: 0.9696 - val_loss: 0.0841 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00311: val_acc did not improve from 0.98734\n",
      "Epoch 312/1000\n",
      "134200/134200 [==============================] - 39s 289us/step - loss: 0.0811 - acc: 0.9704 - val_loss: 0.0697 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00312: val_acc did not improve from 0.98734\n",
      "Epoch 313/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0817 - acc: 0.9700 - val_loss: 0.0620 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00313: val_acc did not improve from 0.98734\n",
      "Epoch 314/1000\n",
      "134200/134200 [==============================] - 35s 262us/step - loss: 0.0825 - acc: 0.9697 - val_loss: 0.0761 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00314: val_acc did not improve from 0.98734\n",
      "Epoch 315/1000\n",
      "134200/134200 [==============================] - 33s 247us/step - loss: 0.0821 - acc: 0.9699 - val_loss: 0.0598 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00315: val_acc did not improve from 0.98734\n",
      "Epoch 316/1000\n",
      "134200/134200 [==============================] - 32s 239us/step - loss: 0.0805 - acc: 0.9698 - val_loss: 0.0554 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00316: val_acc did not improve from 0.98734\n",
      "Epoch 317/1000\n",
      "134200/134200 [==============================] - 33s 244us/step - loss: 0.0819 - acc: 0.9703 - val_loss: 0.0658 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00317: val_acc did not improve from 0.98734\n",
      "Epoch 318/1000\n",
      "134200/134200 [==============================] - 38s 282us/step - loss: 0.0815 - acc: 0.9700 - val_loss: 0.0594 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00318: val_acc did not improve from 0.98734\n",
      "Epoch 319/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0802 - acc: 0.9704 - val_loss: 0.0656 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00319: val_acc did not improve from 0.98734\n",
      "Epoch 320/1000\n",
      "134200/134200 [==============================] - 32s 236us/step - loss: 0.0817 - acc: 0.9697 - val_loss: 0.0611 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00320: val_acc did not improve from 0.98734\n",
      "Epoch 321/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0816 - acc: 0.9697 - val_loss: 0.0610 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00321: val_acc did not improve from 0.98734\n",
      "Epoch 322/1000\n",
      "134200/134200 [==============================] - 33s 244us/step - loss: 0.0806 - acc: 0.9706 - val_loss: 0.0560 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00322: val_acc did not improve from 0.98734\n",
      "Epoch 323/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0809 - acc: 0.9703 - val_loss: 0.0610 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00323: val_acc did not improve from 0.98734\n",
      "Epoch 324/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0813 - acc: 0.9700 - val_loss: 0.0827 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00324: val_acc did not improve from 0.98734\n",
      "Epoch 325/1000\n",
      "134200/134200 [==============================] - 34s 251us/step - loss: 0.0814 - acc: 0.9698 - val_loss: 0.0814 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00325: val_acc did not improve from 0.98734\n",
      "Epoch 326/1000\n",
      "134200/134200 [==============================] - 32s 237us/step - loss: 0.0816 - acc: 0.9698 - val_loss: 0.0628 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00326: val_acc did not improve from 0.98734\n",
      "Epoch 327/1000\n",
      "134200/134200 [==============================] - 32s 239us/step - loss: 0.0812 - acc: 0.9700 - val_loss: 0.0594 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00327: val_acc did not improve from 0.98734\n",
      "Epoch 328/1000\n",
      "134200/134200 [==============================] - 32s 237us/step - loss: 0.0814 - acc: 0.9701 - val_loss: 0.0654 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00328: val_acc did not improve from 0.98734\n",
      "Epoch 329/1000\n",
      "134200/134200 [==============================] - 33s 249us/step - loss: 0.0808 - acc: 0.9704 - val_loss: 0.0573 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00329: val_acc did not improve from 0.98734\n",
      "Epoch 330/1000\n",
      "134200/134200 [==============================] - 32s 237us/step - loss: 0.0821 - acc: 0.9701 - val_loss: 0.0604 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00330: val_acc did not improve from 0.98734\n",
      "Epoch 331/1000\n",
      "134200/134200 [==============================] - 32s 236us/step - loss: 0.0821 - acc: 0.9698 - val_loss: 0.0529 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00331: val_acc did not improve from 0.98734\n",
      "Epoch 332/1000\n",
      "134200/134200 [==============================] - 34s 255us/step - loss: 0.0818 - acc: 0.9699 - val_loss: 0.0678 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00332: val_acc did not improve from 0.98734\n",
      "Epoch 333/1000\n",
      "134200/134200 [==============================] - 35s 262us/step - loss: 0.0806 - acc: 0.9704 - val_loss: 0.0705 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00333: val_acc did not improve from 0.98734\n",
      "Epoch 334/1000\n",
      "134200/134200 [==============================] - 34s 250us/step - loss: 0.0807 - acc: 0.9703 - val_loss: 0.0793 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00334: val_acc did not improve from 0.98734\n",
      "Epoch 335/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0818 - acc: 0.9699 - val_loss: 0.0697 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00335: val_acc did not improve from 0.98734\n",
      "Epoch 336/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 33s 244us/step - loss: 0.0817 - acc: 0.9699 - val_loss: 0.0581 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00336: val_acc did not improve from 0.98734\n",
      "Epoch 337/1000\n",
      "134200/134200 [==============================] - 33s 246us/step - loss: 0.0818 - acc: 0.9698 - val_loss: 0.0735 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00337: val_acc did not improve from 0.98734\n",
      "Epoch 338/1000\n",
      "134200/134200 [==============================] - 33s 245us/step - loss: 0.0802 - acc: 0.9703 - val_loss: 0.0574 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00338: val_acc did not improve from 0.98734\n",
      "Epoch 339/1000\n",
      "134200/134200 [==============================] - 33s 243us/step - loss: 0.0804 - acc: 0.9703 - val_loss: 0.1058 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00339: val_acc did not improve from 0.98734\n",
      "Epoch 340/1000\n",
      "134200/134200 [==============================] - 33s 246us/step - loss: 0.0806 - acc: 0.9705 - val_loss: 0.0617 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00340: val_acc did not improve from 0.98734\n",
      "Epoch 341/1000\n",
      "134200/134200 [==============================] - 33s 246us/step - loss: 0.0813 - acc: 0.9702 - val_loss: 0.0737 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00341: val_acc did not improve from 0.98734\n",
      "Epoch 342/1000\n",
      "134200/134200 [==============================] - 35s 261us/step - loss: 0.0815 - acc: 0.9702 - val_loss: 0.0634 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00342: val_acc did not improve from 0.98734\n",
      "Epoch 343/1000\n",
      "134200/134200 [==============================] - 33s 245us/step - loss: 0.0811 - acc: 0.9697 - val_loss: 0.0612 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00343: val_acc did not improve from 0.98734\n",
      "Epoch 344/1000\n",
      "134200/134200 [==============================] - 31s 234us/step - loss: 0.0820 - acc: 0.9698 - val_loss: 0.0677 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00344: val_acc did not improve from 0.98734\n",
      "Epoch 345/1000\n",
      "134200/134200 [==============================] - 32s 239us/step - loss: 0.0813 - acc: 0.9699 - val_loss: 0.0842 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00345: val_acc did not improve from 0.98734\n",
      "Epoch 346/1000\n",
      "134200/134200 [==============================] - 33s 243us/step - loss: 0.0812 - acc: 0.9702 - val_loss: 0.0744 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00346: val_acc did not improve from 0.98734\n",
      "Epoch 347/1000\n",
      "134200/134200 [==============================] - 33s 248us/step - loss: 0.0822 - acc: 0.9700 - val_loss: 0.0731 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00347: val_acc did not improve from 0.98734\n",
      "Epoch 348/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0804 - acc: 0.9699 - val_loss: 0.1030 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00348: val_acc did not improve from 0.98734\n",
      "Epoch 349/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0807 - acc: 0.9699 - val_loss: 0.0822 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00349: val_acc did not improve from 0.98734\n",
      "Epoch 350/1000\n",
      "134200/134200 [==============================] - 41s 304us/step - loss: 0.0815 - acc: 0.9699 - val_loss: 0.0594 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00350: val_acc did not improve from 0.98734\n",
      "Epoch 351/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0806 - acc: 0.9700 - val_loss: 0.0986 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00351: val_acc did not improve from 0.98734\n",
      "Epoch 352/1000\n",
      "134200/134200 [==============================] - 35s 263us/step - loss: 0.0807 - acc: 0.9703 - val_loss: 0.0641 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00352: val_acc did not improve from 0.98734\n",
      "Epoch 353/1000\n",
      "134200/134200 [==============================] - 43s 318us/step - loss: 0.0810 - acc: 0.9697 - val_loss: 0.0828 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00353: val_acc did not improve from 0.98734\n",
      "Epoch 354/1000\n",
      "134200/134200 [==============================] - 34s 256us/step - loss: 0.0814 - acc: 0.9700 - val_loss: 0.0571 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00354: val_acc did not improve from 0.98734\n",
      "Epoch 355/1000\n",
      "134200/134200 [==============================] - 34s 256us/step - loss: 0.0823 - acc: 0.9693 - val_loss: 0.0640 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00355: val_acc did not improve from 0.98734\n",
      "Epoch 356/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0819 - acc: 0.9692 - val_loss: 0.0680 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00356: val_acc did not improve from 0.98734\n",
      "Epoch 357/1000\n",
      "134200/134200 [==============================] - 32s 241us/step - loss: 0.0814 - acc: 0.9699 - val_loss: 0.0709 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00357: val_acc did not improve from 0.98734\n",
      "Epoch 358/1000\n",
      "134200/134200 [==============================] - 39s 293us/step - loss: 0.0815 - acc: 0.9694 - val_loss: 0.0747 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00358: val_acc did not improve from 0.98734\n",
      "Epoch 359/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0819 - acc: 0.9697 - val_loss: 0.0669 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00359: val_acc did not improve from 0.98734\n",
      "Epoch 360/1000\n",
      "134200/134200 [==============================] - 34s 256us/step - loss: 0.0822 - acc: 0.9694 - val_loss: 0.0553 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00360: val_acc did not improve from 0.98734\n",
      "Epoch 361/1000\n",
      "134200/134200 [==============================] - 36s 265us/step - loss: 0.0819 - acc: 0.9700 - val_loss: 0.0870 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00361: val_acc did not improve from 0.98734\n",
      "Epoch 362/1000\n",
      "134200/134200 [==============================] - 35s 262us/step - loss: 0.0803 - acc: 0.9704 - val_loss: 0.0613 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00362: val_acc did not improve from 0.98734\n",
      "Epoch 363/1000\n",
      "134200/134200 [==============================] - 33s 248us/step - loss: 0.0813 - acc: 0.9694 - val_loss: 0.0873 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00363: val_acc did not improve from 0.98734\n",
      "Epoch 364/1000\n",
      "134200/134200 [==============================] - 34s 250us/step - loss: 0.0823 - acc: 0.9692 - val_loss: 0.0679 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00364: val_acc did not improve from 0.98734\n",
      "Epoch 365/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0822 - acc: 0.9701 - val_loss: 0.0740 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00365: val_acc did not improve from 0.98734\n",
      "Epoch 366/1000\n",
      "134200/134200 [==============================] - 35s 260us/step - loss: 0.0822 - acc: 0.9695 - val_loss: 0.0603 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00366: val_acc did not improve from 0.98734\n",
      "Epoch 367/1000\n",
      "134200/134200 [==============================] - 47s 351us/step - loss: 0.0814 - acc: 0.9694 - val_loss: 0.0694 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00367: val_acc did not improve from 0.98734\n",
      "Epoch 368/1000\n",
      "134200/134200 [==============================] - 34s 254us/step - loss: 0.0796 - acc: 0.9705 - val_loss: 0.0627 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00368: val_acc did not improve from 0.98734\n",
      "Epoch 369/1000\n",
      "134200/134200 [==============================] - 39s 287us/step - loss: 0.0817 - acc: 0.9697 - val_loss: 0.0678 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00369: val_acc did not improve from 0.98734\n",
      "Epoch 370/1000\n",
      "134200/134200 [==============================] - 48s 356us/step - loss: 0.0830 - acc: 0.9693 - val_loss: 0.0608 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00370: val_acc did not improve from 0.98734\n",
      "Epoch 371/1000\n",
      "134200/134200 [==============================] - 53s 395us/step - loss: 0.0817 - acc: 0.9703 - val_loss: 0.0670 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00371: val_acc did not improve from 0.98734\n",
      "Epoch 372/1000\n",
      "134200/134200 [==============================] - 39s 293us/step - loss: 0.0802 - acc: 0.9701 - val_loss: 0.1112 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00372: val_acc did not improve from 0.98734\n",
      "Epoch 373/1000\n",
      "134200/134200 [==============================] - 38s 284us/step - loss: 0.0808 - acc: 0.9698 - val_loss: 0.0899 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00373: val_acc did not improve from 0.98734\n",
      "Epoch 374/1000\n",
      "134200/134200 [==============================] - 39s 287us/step - loss: 0.0810 - acc: 0.9701 - val_loss: 0.0590 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00374: val_acc did not improve from 0.98734\n",
      "Epoch 375/1000\n",
      "134200/134200 [==============================] - 43s 318us/step - loss: 0.0808 - acc: 0.9698 - val_loss: 0.0710 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00375: val_acc did not improve from 0.98734\n",
      "Epoch 376/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0813 - acc: 0.9704 - val_loss: 0.0594 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00376: val_acc did not improve from 0.98734\n",
      "Epoch 377/1000\n",
      "134200/134200 [==============================] - 34s 256us/step - loss: 0.0819 - acc: 0.9695 - val_loss: 0.1063 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00377: val_acc did not improve from 0.98734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000\n",
      "134200/134200 [==============================] - 41s 305us/step - loss: 0.0811 - acc: 0.9700 - val_loss: 0.0602 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00378: val_acc did not improve from 0.98734\n",
      "Epoch 379/1000\n",
      "134200/134200 [==============================] - 35s 260us/step - loss: 0.0802 - acc: 0.9705 - val_loss: 0.1065 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00379: val_acc did not improve from 0.98734\n",
      "Epoch 380/1000\n",
      "134200/134200 [==============================] - 39s 290us/step - loss: 0.0810 - acc: 0.9707 - val_loss: 0.0663 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00380: val_acc did not improve from 0.98734\n",
      "Epoch 381/1000\n",
      "134200/134200 [==============================] - 33s 242us/step - loss: 0.0822 - acc: 0.9697 - val_loss: 0.0676 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00381: val_acc did not improve from 0.98734\n",
      "Epoch 382/1000\n",
      "134200/134200 [==============================] - 41s 306us/step - loss: 0.0803 - acc: 0.9702 - val_loss: 0.0562 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00382: val_acc did not improve from 0.98734\n",
      "Epoch 383/1000\n",
      "134200/134200 [==============================] - 44s 328us/step - loss: 0.0808 - acc: 0.9702 - val_loss: 0.0583 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00383: val_acc did not improve from 0.98734\n",
      "Epoch 384/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0824 - acc: 0.9697 - val_loss: 0.0691 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00384: val_acc did not improve from 0.98734\n",
      "Epoch 385/1000\n",
      "134200/134200 [==============================] - 37s 277us/step - loss: 0.0804 - acc: 0.9702 - val_loss: 0.0527 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00385: val_acc did not improve from 0.98734\n",
      "Epoch 386/1000\n",
      "134200/134200 [==============================] - 42s 314us/step - loss: 0.0808 - acc: 0.9701 - val_loss: 0.0642 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00386: val_acc did not improve from 0.98734\n",
      "Epoch 387/1000\n",
      "134200/134200 [==============================] - 41s 302us/step - loss: 0.0808 - acc: 0.9701 - val_loss: 0.0564 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00387: val_acc did not improve from 0.98734\n",
      "Epoch 388/1000\n",
      "134200/134200 [==============================] - 52s 391us/step - loss: 0.0804 - acc: 0.9700 - val_loss: 0.1019 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00388: val_acc did not improve from 0.98734\n",
      "Epoch 389/1000\n",
      "134200/134200 [==============================] - 56s 414us/step - loss: 0.0810 - acc: 0.9702 - val_loss: 0.0692 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00389: val_acc did not improve from 0.98734\n",
      "Epoch 390/1000\n",
      "134200/134200 [==============================] - 33s 247us/step - loss: 0.0829 - acc: 0.9698 - val_loss: 0.0549 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00390: val_acc did not improve from 0.98734\n",
      "Epoch 391/1000\n",
      "134200/134200 [==============================] - 40s 297us/step - loss: 0.0808 - acc: 0.9698 - val_loss: 0.0672 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00391: val_acc did not improve from 0.98734\n",
      "Epoch 392/1000\n",
      "134200/134200 [==============================] - 39s 288us/step - loss: 0.0806 - acc: 0.9697 - val_loss: 0.0543 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00392: val_acc did not improve from 0.98734\n",
      "Epoch 393/1000\n",
      "134200/134200 [==============================] - 34s 253us/step - loss: 0.0807 - acc: 0.9699 - val_loss: 0.0711 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00393: val_acc did not improve from 0.98734\n",
      "Epoch 394/1000\n",
      "134200/134200 [==============================] - 1837s 14ms/step - loss: 0.0809 - acc: 0.9699 - val_loss: 0.0978 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00394: val_acc did not improve from 0.98734\n",
      "Epoch 395/1000\n",
      "134200/134200 [==============================] - 47s 350us/step - loss: 0.0805 - acc: 0.9704 - val_loss: 0.0685 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00395: val_acc did not improve from 0.98734\n",
      "Epoch 396/1000\n",
      "134200/134200 [==============================] - 48s 358us/step - loss: 0.0813 - acc: 0.9700 - val_loss: 0.0631 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00396: val_acc did not improve from 0.98734\n",
      "Epoch 397/1000\n",
      "134200/134200 [==============================] - 42s 315us/step - loss: 0.0798 - acc: 0.9708 - val_loss: 0.0676 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00397: val_acc did not improve from 0.98734\n",
      "Epoch 398/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0808 - acc: 0.9701 - val_loss: 0.0597 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00398: val_acc did not improve from 0.98734\n",
      "Epoch 399/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0819 - acc: 0.9701 - val_loss: 0.0652 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00399: val_acc did not improve from 0.98734\n",
      "Epoch 400/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0810 - acc: 0.9697 - val_loss: 0.0659 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00400: val_acc did not improve from 0.98734\n",
      "Epoch 401/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0802 - acc: 0.9700 - val_loss: 0.0585 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00401: val_acc did not improve from 0.98734\n",
      "Epoch 402/1000\n",
      "134200/134200 [==============================] - 40s 298us/step - loss: 0.0808 - acc: 0.9707 - val_loss: 0.1641 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00402: val_acc did not improve from 0.98734\n",
      "Epoch 403/1000\n",
      "134200/134200 [==============================] - 38s 282us/step - loss: 0.0822 - acc: 0.9698 - val_loss: 0.0610 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00403: val_acc did not improve from 0.98734\n",
      "Epoch 404/1000\n",
      "134200/134200 [==============================] - 38s 280us/step - loss: 0.0803 - acc: 0.9701 - val_loss: 0.0887 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00404: val_acc did not improve from 0.98734\n",
      "Epoch 405/1000\n",
      "134200/134200 [==============================] - 37s 272us/step - loss: 0.0814 - acc: 0.9699 - val_loss: 0.1668 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00405: val_acc did not improve from 0.98734\n",
      "Epoch 406/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0813 - acc: 0.9700 - val_loss: 0.0846 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00406: val_acc did not improve from 0.98734\n",
      "Epoch 407/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0798 - acc: 0.9703 - val_loss: 0.0964 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00407: val_acc did not improve from 0.98734\n",
      "Epoch 408/1000\n",
      "134200/134200 [==============================] - 38s 282us/step - loss: 0.0824 - acc: 0.9697 - val_loss: 0.0651 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00408: val_acc did not improve from 0.98734\n",
      "Epoch 409/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0794 - acc: 0.9705 - val_loss: 0.0580 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00409: val_acc did not improve from 0.98734\n",
      "Epoch 410/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0809 - acc: 0.9697 - val_loss: 0.0618 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00410: val_acc did not improve from 0.98734\n",
      "Epoch 411/1000\n",
      "134200/134200 [==============================] - 40s 300us/step - loss: 0.0814 - acc: 0.9696 - val_loss: 0.0756 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00411: val_acc did not improve from 0.98734\n",
      "Epoch 412/1000\n",
      "134200/134200 [==============================] - 39s 290us/step - loss: 0.0817 - acc: 0.9694 - val_loss: 0.0639 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00412: val_acc did not improve from 0.98734\n",
      "Epoch 413/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0817 - acc: 0.9697 - val_loss: 0.0542 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00413: val_acc did not improve from 0.98734\n",
      "Epoch 414/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0802 - acc: 0.9705 - val_loss: 0.0726 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00414: val_acc did not improve from 0.98734\n",
      "Epoch 415/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0810 - acc: 0.9701 - val_loss: 0.0611 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00415: val_acc did not improve from 0.98734\n",
      "Epoch 416/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0825 - acc: 0.9696 - val_loss: 0.0646 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00416: val_acc did not improve from 0.98734\n",
      "Epoch 417/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0806 - acc: 0.9702 - val_loss: 0.0663 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00417: val_acc did not improve from 0.98734\n",
      "Epoch 418/1000\n",
      "134200/134200 [==============================] - 43s 319us/step - loss: 0.0818 - acc: 0.9697 - val_loss: 0.0755 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00418: val_acc did not improve from 0.98734\n",
      "Epoch 419/1000\n",
      "134200/134200 [==============================] - 66s 493us/step - loss: 0.0818 - acc: 0.9700 - val_loss: 0.0750 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00419: val_acc did not improve from 0.98734\n",
      "Epoch 420/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 60s 446us/step - loss: 0.0807 - acc: 0.9700 - val_loss: 0.0555 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00420: val_acc did not improve from 0.98734\n",
      "Epoch 421/1000\n",
      "134200/134200 [==============================] - 61s 451us/step - loss: 0.0819 - acc: 0.9694 - val_loss: 0.0644 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00421: val_acc did not improve from 0.98734\n",
      "Epoch 422/1000\n",
      "134200/134200 [==============================] - 62s 461us/step - loss: 0.0798 - acc: 0.9704 - val_loss: 0.0590 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00422: val_acc did not improve from 0.98734\n",
      "Epoch 423/1000\n",
      "134200/134200 [==============================] - 63s 467us/step - loss: 0.0812 - acc: 0.9697 - val_loss: 0.0622 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00423: val_acc did not improve from 0.98734\n",
      "Epoch 424/1000\n",
      "134200/134200 [==============================] - 66s 489us/step - loss: 0.0804 - acc: 0.9695 - val_loss: 0.0740 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00424: val_acc did not improve from 0.98734\n",
      "Epoch 425/1000\n",
      "134200/134200 [==============================] - 64s 476us/step - loss: 0.0821 - acc: 0.9696 - val_loss: 0.0677 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00425: val_acc did not improve from 0.98734\n",
      "Epoch 426/1000\n",
      "134200/134200 [==============================] - 60s 446us/step - loss: 0.0804 - acc: 0.9703 - val_loss: 0.0738 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00426: val_acc did not improve from 0.98734\n",
      "Epoch 427/1000\n",
      "134200/134200 [==============================] - 58s 430us/step - loss: 0.0804 - acc: 0.9705 - val_loss: 0.1678 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00427: val_acc did not improve from 0.98734\n",
      "Epoch 428/1000\n",
      "134200/134200 [==============================] - 60s 446us/step - loss: 0.0813 - acc: 0.9699 - val_loss: 0.0691 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00428: val_acc did not improve from 0.98734\n",
      "Epoch 429/1000\n",
      "134200/134200 [==============================] - 69s 512us/step - loss: 0.0802 - acc: 0.9700 - val_loss: 0.0575 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00429: val_acc did not improve from 0.98734\n",
      "Epoch 430/1000\n",
      "134200/134200 [==============================] - 80s 594us/step - loss: 0.0802 - acc: 0.9701 - val_loss: 0.0638 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00430: val_acc did not improve from 0.98734\n",
      "Epoch 431/1000\n",
      "134200/134200 [==============================] - 58s 431us/step - loss: 0.0808 - acc: 0.9701 - val_loss: 0.0890 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00431: val_acc did not improve from 0.98734\n",
      "Epoch 432/1000\n",
      "134200/134200 [==============================] - 3658s 27ms/step - loss: 0.0813 - acc: 0.9695 - val_loss: 0.0994 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00432: val_acc did not improve from 0.98734\n",
      "Epoch 433/1000\n",
      "134200/134200 [==============================] - 38s 281us/step - loss: 0.0811 - acc: 0.9699 - val_loss: 0.0656 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00433: val_acc did not improve from 0.98734\n",
      "Epoch 434/1000\n",
      "134200/134200 [==============================] - 39s 291us/step - loss: 0.0812 - acc: 0.9700 - val_loss: 0.0972 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00434: val_acc did not improve from 0.98734\n",
      "Epoch 435/1000\n",
      "134200/134200 [==============================] - 36s 269us/step - loss: 0.0800 - acc: 0.9703 - val_loss: 0.0682 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00435: val_acc did not improve from 0.98734\n",
      "Epoch 436/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0801 - acc: 0.9704 - val_loss: 0.0694 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00436: val_acc did not improve from 0.98734\n",
      "Epoch 437/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0798 - acc: 0.9706 - val_loss: 0.0668 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00437: val_acc did not improve from 0.98734\n",
      "Epoch 438/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0827 - acc: 0.9694 - val_loss: 0.0654 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00438: val_acc did not improve from 0.98734\n",
      "Epoch 439/1000\n",
      "134200/134200 [==============================] - 36s 270us/step - loss: 0.0813 - acc: 0.9697 - val_loss: 0.0914 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00439: val_acc did not improve from 0.98734\n",
      "Epoch 440/1000\n",
      "134200/134200 [==============================] - 36s 272us/step - loss: 0.0810 - acc: 0.9704 - val_loss: 0.0898 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00440: val_acc did not improve from 0.98734\n",
      "Epoch 441/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0815 - acc: 0.9696 - val_loss: 0.1095 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00441: val_acc did not improve from 0.98734\n",
      "Epoch 442/1000\n",
      "134200/134200 [==============================] - 39s 291us/step - loss: 0.0824 - acc: 0.9696 - val_loss: 0.0557 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00442: val_acc did not improve from 0.98734\n",
      "Epoch 443/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0813 - acc: 0.9700 - val_loss: 0.0605 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00443: val_acc did not improve from 0.98734\n",
      "Epoch 444/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0817 - acc: 0.9698 - val_loss: 0.0586 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00444: val_acc did not improve from 0.98734\n",
      "Epoch 445/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0806 - acc: 0.9701 - val_loss: 0.0707 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00445: val_acc did not improve from 0.98734\n",
      "Epoch 446/1000\n",
      "134200/134200 [==============================] - 37s 272us/step - loss: 0.0799 - acc: 0.9702 - val_loss: 0.0585 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00446: val_acc did not improve from 0.98734\n",
      "Epoch 447/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0807 - acc: 0.9700 - val_loss: 0.0684 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00447: val_acc did not improve from 0.98734\n",
      "Epoch 448/1000\n",
      "134200/134200 [==============================] - 36s 272us/step - loss: 0.0800 - acc: 0.9702 - val_loss: 0.0724 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00448: val_acc did not improve from 0.98734\n",
      "Epoch 449/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0798 - acc: 0.9709 - val_loss: 0.0669 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00449: val_acc did not improve from 0.98734\n",
      "Epoch 450/1000\n",
      "134200/134200 [==============================] - 38s 281us/step - loss: 0.0806 - acc: 0.9701 - val_loss: 0.0730 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00450: val_acc did not improve from 0.98734\n",
      "Epoch 451/1000\n",
      "134200/134200 [==============================] - 41s 308us/step - loss: 0.0799 - acc: 0.9701 - val_loss: 0.0701 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00451: val_acc did not improve from 0.98734\n",
      "Epoch 452/1000\n",
      "134200/134200 [==============================] - 37s 272us/step - loss: 0.0805 - acc: 0.9704 - val_loss: 0.4889 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00452: val_acc did not improve from 0.98734\n",
      "Epoch 453/1000\n",
      "134200/134200 [==============================] - 36s 269us/step - loss: 0.0820 - acc: 0.9696 - val_loss: 0.0661 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00453: val_acc did not improve from 0.98734\n",
      "Epoch 454/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0797 - acc: 0.9705 - val_loss: 0.0697 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00454: val_acc did not improve from 0.98734\n",
      "Epoch 455/1000\n",
      "134200/134200 [==============================] - 37s 277us/step - loss: 0.0801 - acc: 0.9704 - val_loss: 0.0748 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00455: val_acc did not improve from 0.98734\n",
      "Epoch 456/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0802 - acc: 0.9702 - val_loss: 0.0653 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00456: val_acc did not improve from 0.98734\n",
      "Epoch 457/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0808 - acc: 0.9700 - val_loss: 0.0614 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00457: val_acc did not improve from 0.98734\n",
      "Epoch 458/1000\n",
      "134200/134200 [==============================] - 37s 278us/step - loss: 0.0804 - acc: 0.9704 - val_loss: 0.0886 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00458: val_acc did not improve from 0.98734\n",
      "Epoch 459/1000\n",
      "134200/134200 [==============================] - 40s 301us/step - loss: 0.0807 - acc: 0.9700 - val_loss: 0.0594 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00459: val_acc did not improve from 0.98734\n",
      "Epoch 460/1000\n",
      "134200/134200 [==============================] - 38s 284us/step - loss: 0.0794 - acc: 0.9705 - val_loss: 0.1038 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00460: val_acc did not improve from 0.98734\n",
      "Epoch 461/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0806 - acc: 0.9703 - val_loss: 0.0718 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00461: val_acc did not improve from 0.98734\n",
      "Epoch 462/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 37s 272us/step - loss: 0.0797 - acc: 0.9709 - val_loss: 0.0691 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00462: val_acc did not improve from 0.98734\n",
      "Epoch 463/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0799 - acc: 0.9701 - val_loss: 0.1078 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00463: val_acc did not improve from 0.98734\n",
      "Epoch 464/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0803 - acc: 0.9704 - val_loss: 0.0676 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00464: val_acc did not improve from 0.98734\n",
      "Epoch 465/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0807 - acc: 0.9703 - val_loss: 0.0712 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00465: val_acc did not improve from 0.98734\n",
      "Epoch 466/1000\n",
      "134200/134200 [==============================] - 37s 278us/step - loss: 0.0805 - acc: 0.9703 - val_loss: 0.1558 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00466: val_acc did not improve from 0.98734\n",
      "Epoch 467/1000\n",
      "134200/134200 [==============================] - 40s 298us/step - loss: 0.0803 - acc: 0.9703 - val_loss: 0.0891 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00467: val_acc did not improve from 0.98734\n",
      "Epoch 468/1000\n",
      "134200/134200 [==============================] - 40s 295us/step - loss: 0.0818 - acc: 0.9695 - val_loss: 0.0640 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00468: val_acc did not improve from 0.98734\n",
      "Epoch 469/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0807 - acc: 0.9695 - val_loss: 0.0644 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00469: val_acc did not improve from 0.98734\n",
      "Epoch 470/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0806 - acc: 0.9704 - val_loss: 0.0638 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00470: val_acc did not improve from 0.98734\n",
      "Epoch 471/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0810 - acc: 0.9700 - val_loss: 0.0802 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00471: val_acc did not improve from 0.98734\n",
      "Epoch 472/1000\n",
      "134200/134200 [==============================] - 38s 285us/step - loss: 0.0812 - acc: 0.9699 - val_loss: 0.1231 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00472: val_acc did not improve from 0.98734\n",
      "Epoch 473/1000\n",
      "134200/134200 [==============================] - 38s 282us/step - loss: 0.0806 - acc: 0.9702 - val_loss: 0.0813 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00473: val_acc did not improve from 0.98734\n",
      "Epoch 474/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0796 - acc: 0.9703 - val_loss: 0.0959 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00474: val_acc did not improve from 0.98734\n",
      "Epoch 475/1000\n",
      "134200/134200 [==============================] - 39s 290us/step - loss: 0.0803 - acc: 0.9706 - val_loss: 0.0710 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00475: val_acc did not improve from 0.98734\n",
      "Epoch 476/1000\n",
      "134200/134200 [==============================] - 38s 281us/step - loss: 0.0816 - acc: 0.9698 - val_loss: 0.0669 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00476: val_acc did not improve from 0.98734\n",
      "Epoch 477/1000\n",
      "134200/134200 [==============================] - 41s 305us/step - loss: 0.0803 - acc: 0.9701 - val_loss: 0.0887 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00477: val_acc did not improve from 0.98734\n",
      "Epoch 478/1000\n",
      "134200/134200 [==============================] - 47s 353us/step - loss: 0.0806 - acc: 0.9703 - val_loss: 0.0652 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00478: val_acc did not improve from 0.98734\n",
      "Epoch 479/1000\n",
      "134200/134200 [==============================] - 48s 361us/step - loss: 0.0805 - acc: 0.9700 - val_loss: 0.0642 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00479: val_acc did not improve from 0.98734\n",
      "Epoch 480/1000\n",
      "134200/134200 [==============================] - 2217s 17ms/step - loss: 0.0804 - acc: 0.9701 - val_loss: 0.0633 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00480: val_acc did not improve from 0.98734\n",
      "Epoch 481/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0805 - acc: 0.9702 - val_loss: 0.0627 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00481: val_acc did not improve from 0.98734\n",
      "Epoch 482/1000\n",
      "134200/134200 [==============================] - 39s 289us/step - loss: 0.0815 - acc: 0.9700 - val_loss: 0.0767 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00482: val_acc did not improve from 0.98734\n",
      "Epoch 483/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0793 - acc: 0.9705 - val_loss: 0.0661 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00483: val_acc did not improve from 0.98734\n",
      "Epoch 484/1000\n",
      "134200/134200 [==============================] - 35s 264us/step - loss: 0.0787 - acc: 0.9707 - val_loss: 0.0660 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00484: val_acc did not improve from 0.98734\n",
      "Epoch 485/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0807 - acc: 0.9699 - val_loss: 0.0877 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00485: val_acc did not improve from 0.98734\n",
      "Epoch 486/1000\n",
      "134200/134200 [==============================] - 36s 269us/step - loss: 0.0795 - acc: 0.9706 - val_loss: 0.0881 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00486: val_acc did not improve from 0.98734\n",
      "Epoch 487/1000\n",
      "134200/134200 [==============================] - 36s 267us/step - loss: 0.0797 - acc: 0.9702 - val_loss: 0.0660 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00487: val_acc did not improve from 0.98734\n",
      "Epoch 488/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0798 - acc: 0.9701 - val_loss: 0.0685 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00488: val_acc did not improve from 0.98734\n",
      "Epoch 489/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0802 - acc: 0.9703 - val_loss: 0.0799 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00489: val_acc did not improve from 0.98734\n",
      "Epoch 490/1000\n",
      "134200/134200 [==============================] - 40s 298us/step - loss: 0.0789 - acc: 0.9703 - val_loss: 0.0822 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00490: val_acc did not improve from 0.98734\n",
      "Epoch 491/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0797 - acc: 0.9703 - val_loss: 0.0701 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00491: val_acc did not improve from 0.98734\n",
      "Epoch 492/1000\n",
      "134200/134200 [==============================] - 36s 267us/step - loss: 0.0799 - acc: 0.9704 - val_loss: 0.0706 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00492: val_acc did not improve from 0.98734\n",
      "Epoch 493/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0794 - acc: 0.9710 - val_loss: 0.0902 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00493: val_acc did not improve from 0.98734\n",
      "Epoch 494/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0782 - acc: 0.9706 - val_loss: 0.1621 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00494: val_acc did not improve from 0.98734\n",
      "Epoch 495/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0785 - acc: 0.9706 - val_loss: 0.0633 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00495: val_acc did not improve from 0.98734\n",
      "Epoch 496/1000\n",
      "134200/134200 [==============================] - 38s 283us/step - loss: 0.0791 - acc: 0.9707 - val_loss: 0.0807 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00496: val_acc did not improve from 0.98734\n",
      "Epoch 497/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0794 - acc: 0.9703 - val_loss: 0.1046 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00497: val_acc did not improve from 0.98734\n",
      "Epoch 498/1000\n",
      "134200/134200 [==============================] - 39s 294us/step - loss: 0.0806 - acc: 0.9701 - val_loss: 0.0792 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00498: val_acc did not improve from 0.98734\n",
      "Epoch 499/1000\n",
      "134200/134200 [==============================] - 39s 294us/step - loss: 0.0796 - acc: 0.9707 - val_loss: 0.0726 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00499: val_acc did not improve from 0.98734\n",
      "Epoch 500/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0815 - acc: 0.9699 - val_loss: 0.0703 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00500: val_acc did not improve from 0.98734\n",
      "Epoch 501/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0797 - acc: 0.9700 - val_loss: 0.0759 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00501: val_acc did not improve from 0.98734\n",
      "Epoch 502/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0800 - acc: 0.9703 - val_loss: 0.1094 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00502: val_acc did not improve from 0.98734\n",
      "Epoch 503/1000\n",
      "134200/134200 [==============================] - 37s 278us/step - loss: 0.0803 - acc: 0.9704 - val_loss: 0.0623 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00503: val_acc did not improve from 0.98734\n",
      "Epoch 504/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0799 - acc: 0.9705 - val_loss: 0.0615 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00504: val_acc did not improve from 0.98734\n",
      "Epoch 505/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0793 - acc: 0.9707 - val_loss: 0.0768 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00505: val_acc did not improve from 0.98734\n",
      "Epoch 506/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0799 - acc: 0.9706 - val_loss: 0.0653 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00506: val_acc did not improve from 0.98734\n",
      "Epoch 507/1000\n",
      "134200/134200 [==============================] - 40s 301us/step - loss: 0.0796 - acc: 0.9704 - val_loss: 0.0659 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00507: val_acc did not improve from 0.98734\n",
      "Epoch 508/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0803 - acc: 0.9703 - val_loss: 0.0720 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00508: val_acc did not improve from 0.98734\n",
      "Epoch 509/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0799 - acc: 0.9704 - val_loss: 0.0705 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00509: val_acc did not improve from 0.98734\n",
      "Epoch 510/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0786 - acc: 0.9710 - val_loss: 0.0663 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00510: val_acc did not improve from 0.98734\n",
      "Epoch 511/1000\n",
      "134200/134200 [==============================] - 38s 285us/step - loss: 0.0800 - acc: 0.9701 - val_loss: 0.1007 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00511: val_acc did not improve from 0.98734\n",
      "Epoch 512/1000\n",
      "134200/134200 [==============================] - 39s 290us/step - loss: 0.0794 - acc: 0.9704 - val_loss: 0.0696 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00512: val_acc did not improve from 0.98734\n",
      "Epoch 513/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0815 - acc: 0.9698 - val_loss: 0.0902 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00513: val_acc did not improve from 0.98734\n",
      "Epoch 514/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0805 - acc: 0.9699 - val_loss: 0.0662 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00514: val_acc did not improve from 0.98734\n",
      "Epoch 515/1000\n",
      "134200/134200 [==============================] - 38s 284us/step - loss: 0.0790 - acc: 0.9705 - val_loss: 0.0753 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00515: val_acc did not improve from 0.98734\n",
      "Epoch 516/1000\n",
      "134200/134200 [==============================] - 41s 308us/step - loss: 0.0813 - acc: 0.9695 - val_loss: 0.0692 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00516: val_acc did not improve from 0.98734\n",
      "Epoch 517/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0813 - acc: 0.9698 - val_loss: 0.0565 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00517: val_acc did not improve from 0.98734\n",
      "Epoch 518/1000\n",
      "134200/134200 [==============================] - 37s 278us/step - loss: 0.0795 - acc: 0.9705 - val_loss: 0.0704 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00518: val_acc did not improve from 0.98734\n",
      "Epoch 519/1000\n",
      "134200/134200 [==============================] - 38s 280us/step - loss: 0.0784 - acc: 0.9711 - val_loss: 0.0741 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00519: val_acc did not improve from 0.98734\n",
      "Epoch 520/1000\n",
      "134200/134200 [==============================] - 37s 278us/step - loss: 0.0809 - acc: 0.9700 - val_loss: 0.0832 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00520: val_acc did not improve from 0.98734\n",
      "Epoch 521/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0792 - acc: 0.9706 - val_loss: 0.0990 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00521: val_acc did not improve from 0.98734\n",
      "Epoch 522/1000\n",
      "134200/134200 [==============================] - 49s 362us/step - loss: 0.0798 - acc: 0.9702 - val_loss: 0.0927 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00522: val_acc did not improve from 0.98734\n",
      "Epoch 523/1000\n",
      "134200/134200 [==============================] - 52s 384us/step - loss: 0.0814 - acc: 0.9698 - val_loss: 0.0902 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00523: val_acc did not improve from 0.98734\n",
      "Epoch 524/1000\n",
      "134200/134200 [==============================] - 54s 403us/step - loss: 0.0795 - acc: 0.9705 - val_loss: 0.0657 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00524: val_acc did not improve from 0.98734\n",
      "Epoch 525/1000\n",
      "134200/134200 [==============================] - 49s 368us/step - loss: 0.0799 - acc: 0.9703 - val_loss: 0.0561 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00525: val_acc did not improve from 0.98734\n",
      "Epoch 526/1000\n",
      "134200/134200 [==============================] - 50s 371us/step - loss: 0.0781 - acc: 0.9704 - val_loss: 0.0754 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00526: val_acc did not improve from 0.98734\n",
      "Epoch 527/1000\n",
      "134200/134200 [==============================] - 3648s 27ms/step - loss: 0.0795 - acc: 0.9705 - val_loss: 0.0671 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00527: val_acc did not improve from 0.98734\n",
      "Epoch 528/1000\n",
      "134200/134200 [==============================] - 41s 302us/step - loss: 0.0796 - acc: 0.9708 - val_loss: 0.0647 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00528: val_acc did not improve from 0.98734\n",
      "Epoch 529/1000\n",
      "134200/134200 [==============================] - 36s 269us/step - loss: 0.0785 - acc: 0.9708 - val_loss: 0.0725 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00529: val_acc did not improve from 0.98734\n",
      "Epoch 530/1000\n",
      "134200/134200 [==============================] - 35s 264us/step - loss: 0.0792 - acc: 0.9711 - val_loss: 0.0720 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00530: val_acc did not improve from 0.98734\n",
      "Epoch 531/1000\n",
      "134200/134200 [==============================] - 35s 263us/step - loss: 0.0798 - acc: 0.9703 - val_loss: 0.0655 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00531: val_acc did not improve from 0.98734\n",
      "Epoch 532/1000\n",
      "134200/134200 [==============================] - 36s 265us/step - loss: 0.0804 - acc: 0.9701 - val_loss: 0.0628 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00532: val_acc did not improve from 0.98734\n",
      "Epoch 533/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0797 - acc: 0.9705 - val_loss: 0.0865 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00533: val_acc did not improve from 0.98734\n",
      "Epoch 534/1000\n",
      "134200/134200 [==============================] - 39s 290us/step - loss: 0.0790 - acc: 0.9708 - val_loss: 0.0712 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00534: val_acc did not improve from 0.98734\n",
      "Epoch 535/1000\n",
      "134200/134200 [==============================] - 36s 269us/step - loss: 0.0800 - acc: 0.9702 - val_loss: 0.0703 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00535: val_acc did not improve from 0.98734\n",
      "Epoch 536/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0791 - acc: 0.9704 - val_loss: 0.1428 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00536: val_acc did not improve from 0.98734\n",
      "Epoch 537/1000\n",
      "134200/134200 [==============================] - 40s 300us/step - loss: 0.0787 - acc: 0.9708 - val_loss: 0.0979 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00537: val_acc did not improve from 0.98734\n",
      "Epoch 538/1000\n",
      "134200/134200 [==============================] - 38s 286us/step - loss: 0.0801 - acc: 0.9698 - val_loss: 0.0650 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00538: val_acc did not improve from 0.98734\n",
      "Epoch 539/1000\n",
      "134200/134200 [==============================] - 36s 267us/step - loss: 0.0793 - acc: 0.9706 - val_loss: 0.0839 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00539: val_acc did not improve from 0.98734\n",
      "Epoch 540/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0785 - acc: 0.9709 - val_loss: 0.0636 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00540: val_acc did not improve from 0.98734\n",
      "Epoch 541/1000\n",
      "134200/134200 [==============================] - 37s 272us/step - loss: 0.0796 - acc: 0.9706 - val_loss: 0.0719 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00541: val_acc did not improve from 0.98734\n",
      "Epoch 542/1000\n",
      "134200/134200 [==============================] - 40s 301us/step - loss: 0.0804 - acc: 0.9702 - val_loss: 0.0666 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00542: val_acc did not improve from 0.98734\n",
      "Epoch 543/1000\n",
      "134200/134200 [==============================] - 42s 316us/step - loss: 0.0780 - acc: 0.9715 - val_loss: 0.0753 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00543: val_acc did not improve from 0.98734\n",
      "Epoch 544/1000\n",
      "134200/134200 [==============================] - 36s 270us/step - loss: 0.0794 - acc: 0.9708 - val_loss: 0.0749 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00544: val_acc did not improve from 0.98734\n",
      "Epoch 545/1000\n",
      "134200/134200 [==============================] - 40s 298us/step - loss: 0.0783 - acc: 0.9710 - val_loss: 0.0744 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00545: val_acc did not improve from 0.98734\n",
      "Epoch 546/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0799 - acc: 0.9697 - val_loss: 0.0719 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00546: val_acc did not improve from 0.98734\n",
      "Epoch 547/1000\n",
      "134200/134200 [==============================] - 36s 269us/step - loss: 0.0791 - acc: 0.9709 - val_loss: 0.0821 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00547: val_acc did not improve from 0.98734\n",
      "Epoch 548/1000\n",
      "134200/134200 [==============================] - 37s 272us/step - loss: 0.0806 - acc: 0.9699 - val_loss: 0.0775 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00548: val_acc did not improve from 0.98734\n",
      "Epoch 549/1000\n",
      "134200/134200 [==============================] - 38s 285us/step - loss: 0.0797 - acc: 0.9700 - val_loss: 0.0730 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00549: val_acc did not improve from 0.98734\n",
      "Epoch 550/1000\n",
      "134200/134200 [==============================] - 46s 343us/step - loss: 0.0800 - acc: 0.9702 - val_loss: 0.0764 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00550: val_acc did not improve from 0.98734\n",
      "Epoch 551/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0782 - acc: 0.9709 - val_loss: 0.0703 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00551: val_acc did not improve from 0.98734\n",
      "Epoch 552/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0798 - acc: 0.9705 - val_loss: 0.0748 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00552: val_acc did not improve from 0.98734\n",
      "Epoch 553/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0798 - acc: 0.9703 - val_loss: 0.0733 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00553: val_acc did not improve from 0.98734\n",
      "Epoch 554/1000\n",
      "134200/134200 [==============================] - 40s 300us/step - loss: 0.0788 - acc: 0.9707 - val_loss: 0.0856 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00554: val_acc did not improve from 0.98734\n",
      "Epoch 555/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0789 - acc: 0.9705 - val_loss: 0.0808 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00555: val_acc did not improve from 0.98734\n",
      "Epoch 556/1000\n",
      "134200/134200 [==============================] - 38s 280us/step - loss: 0.0796 - acc: 0.9707 - val_loss: 0.0748 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00556: val_acc did not improve from 0.98734\n",
      "Epoch 557/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0789 - acc: 0.9710 - val_loss: 0.0773 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00557: val_acc did not improve from 0.98734\n",
      "Epoch 558/1000\n",
      "134200/134200 [==============================] - 38s 287us/step - loss: 0.0802 - acc: 0.9701 - val_loss: 0.0589 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00558: val_acc did not improve from 0.98734\n",
      "Epoch 559/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0797 - acc: 0.9704 - val_loss: 0.0742 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00559: val_acc did not improve from 0.98734\n",
      "Epoch 560/1000\n",
      "134200/134200 [==============================] - 36s 272us/step - loss: 0.0803 - acc: 0.9706 - val_loss: 0.0905 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00560: val_acc did not improve from 0.98734\n",
      "Epoch 561/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0800 - acc: 0.9702 - val_loss: 0.0827 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00561: val_acc did not improve from 0.98734\n",
      "Epoch 562/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0797 - acc: 0.9709 - val_loss: 0.0647 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00562: val_acc did not improve from 0.98734\n",
      "Epoch 563/1000\n",
      "134200/134200 [==============================] - 40s 299us/step - loss: 0.0783 - acc: 0.9710 - val_loss: 0.0672 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00563: val_acc did not improve from 0.98734\n",
      "Epoch 564/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0792 - acc: 0.9708 - val_loss: 0.1291 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00564: val_acc did not improve from 0.98734\n",
      "Epoch 565/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0789 - acc: 0.9706 - val_loss: 0.0634 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00565: val_acc did not improve from 0.98734\n",
      "Epoch 566/1000\n",
      "134200/134200 [==============================] - 40s 300us/step - loss: 0.0796 - acc: 0.9705 - val_loss: 0.0697 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00566: val_acc did not improve from 0.98734\n",
      "Epoch 567/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0799 - acc: 0.9701 - val_loss: 0.0893 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00567: val_acc did not improve from 0.98734\n",
      "Epoch 568/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0792 - acc: 0.9709 - val_loss: 0.0815 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00568: val_acc did not improve from 0.98734\n",
      "Epoch 569/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0797 - acc: 0.9704 - val_loss: 0.0787 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00569: val_acc did not improve from 0.98734\n",
      "Epoch 570/1000\n",
      "134200/134200 [==============================] - 36s 272us/step - loss: 0.0798 - acc: 0.9698 - val_loss: 0.1072 - val_acc: 0.9578\n",
      "\n",
      "Epoch 00570: val_acc did not improve from 0.98734\n",
      "Epoch 571/1000\n",
      "134200/134200 [==============================] - 39s 293us/step - loss: 0.0794 - acc: 0.9703 - val_loss: 0.0663 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00571: val_acc did not improve from 0.98734\n",
      "Epoch 572/1000\n",
      "134200/134200 [==============================] - 38s 287us/step - loss: 0.0794 - acc: 0.9701 - val_loss: 0.0649 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00572: val_acc did not improve from 0.98734\n",
      "Epoch 573/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0784 - acc: 0.9709 - val_loss: 0.0619 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00573: val_acc did not improve from 0.98734\n",
      "Epoch 574/1000\n",
      "134200/134200 [==============================] - 44s 330us/step - loss: 0.0800 - acc: 0.9701 - val_loss: 0.0746 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00574: val_acc did not improve from 0.98734\n",
      "Epoch 575/1000\n",
      "134200/134200 [==============================] - 49s 368us/step - loss: 0.0793 - acc: 0.9711 - val_loss: 0.0709 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00575: val_acc did not improve from 0.98734\n",
      "Epoch 576/1000\n",
      "134200/134200 [==============================] - 2049s 15ms/step - loss: 0.0797 - acc: 0.9706 - val_loss: 0.0780 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00576: val_acc did not improve from 0.98734\n",
      "Epoch 577/1000\n",
      "134200/134200 [==============================] - 36s 272us/step - loss: 0.0783 - acc: 0.9707 - val_loss: 0.0793 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00577: val_acc did not improve from 0.98734\n",
      "Epoch 578/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0797 - acc: 0.9705 - val_loss: 0.0644 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00578: val_acc did not improve from 0.98734\n",
      "Epoch 579/1000\n",
      "134200/134200 [==============================] - 35s 262us/step - loss: 0.0796 - acc: 0.9706 - val_loss: 0.0801 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00579: val_acc did not improve from 0.98734\n",
      "Epoch 580/1000\n",
      "134200/134200 [==============================] - 36s 267us/step - loss: 0.0799 - acc: 0.9703 - val_loss: 0.0591 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00580: val_acc did not improve from 0.98734\n",
      "Epoch 581/1000\n",
      "134200/134200 [==============================] - 36s 270us/step - loss: 0.0796 - acc: 0.9705 - val_loss: 0.0695 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00581: val_acc did not improve from 0.98734\n",
      "Epoch 582/1000\n",
      "134200/134200 [==============================] - 38s 285us/step - loss: 0.0791 - acc: 0.9707 - val_loss: 0.0833 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00582: val_acc did not improve from 0.98734\n",
      "Epoch 583/1000\n",
      "134200/134200 [==============================] - 36s 267us/step - loss: 0.0797 - acc: 0.9704 - val_loss: 0.0678 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00583: val_acc did not improve from 0.98734\n",
      "Epoch 584/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0795 - acc: 0.9703 - val_loss: 0.0647 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00584: val_acc did not improve from 0.98734\n",
      "Epoch 585/1000\n",
      "134200/134200 [==============================] - 40s 298us/step - loss: 0.0788 - acc: 0.9709 - val_loss: 0.0740 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00585: val_acc did not improve from 0.98734\n",
      "Epoch 586/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0784 - acc: 0.9711 - val_loss: 0.0734 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00586: val_acc did not improve from 0.98734\n",
      "Epoch 587/1000\n",
      "134200/134200 [==============================] - 36s 270us/step - loss: 0.0794 - acc: 0.9705 - val_loss: 0.0855 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00587: val_acc did not improve from 0.98734\n",
      "Epoch 588/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 36s 267us/step - loss: 0.0780 - acc: 0.9711 - val_loss: 0.0845 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00588: val_acc did not improve from 0.98734\n",
      "Epoch 589/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0798 - acc: 0.9707 - val_loss: 0.0724 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00589: val_acc did not improve from 0.98734\n",
      "Epoch 590/1000\n",
      "134200/134200 [==============================] - 36s 270us/step - loss: 0.0782 - acc: 0.9713 - val_loss: 0.1467 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00590: val_acc did not improve from 0.98734\n",
      "Epoch 591/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0784 - acc: 0.9711 - val_loss: 0.0691 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00591: val_acc did not improve from 0.98734\n",
      "Epoch 592/1000\n",
      "134200/134200 [==============================] - 43s 321us/step - loss: 0.0797 - acc: 0.9708 - val_loss: 0.1270 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00592: val_acc did not improve from 0.98734\n",
      "Epoch 593/1000\n",
      "134200/134200 [==============================] - 44s 329us/step - loss: 0.0795 - acc: 0.9703 - val_loss: 0.1077 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00593: val_acc did not improve from 0.98734\n",
      "Epoch 594/1000\n",
      "134200/134200 [==============================] - 38s 283us/step - loss: 0.0793 - acc: 0.9702 - val_loss: 0.0929 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00594: val_acc did not improve from 0.98734\n",
      "Epoch 595/1000\n",
      "134200/134200 [==============================] - 36s 269us/step - loss: 0.0787 - acc: 0.9710 - val_loss: 0.0704 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00595: val_acc did not improve from 0.98734\n",
      "Epoch 596/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0791 - acc: 0.9705 - val_loss: 0.0795 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00596: val_acc did not improve from 0.98734\n",
      "Epoch 597/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0792 - acc: 0.9699 - val_loss: 0.1299 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00597: val_acc did not improve from 0.98734\n",
      "Epoch 598/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0787 - acc: 0.9708 - val_loss: 0.0734 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00598: val_acc did not improve from 0.98734\n",
      "Epoch 599/1000\n",
      "134200/134200 [==============================] - 36s 270us/step - loss: 0.0795 - acc: 0.9704 - val_loss: 0.0710 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00599: val_acc did not improve from 0.98734\n",
      "Epoch 600/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0797 - acc: 0.9702 - val_loss: 0.0674 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00600: val_acc did not improve from 0.98734\n",
      "Epoch 601/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0805 - acc: 0.9702 - val_loss: 0.1522 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00601: val_acc did not improve from 0.98734\n",
      "Epoch 602/1000\n",
      "134200/134200 [==============================] - 40s 299us/step - loss: 0.0797 - acc: 0.9704 - val_loss: 0.0586 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00602: val_acc did not improve from 0.98734\n",
      "Epoch 603/1000\n",
      "134200/134200 [==============================] - 38s 282us/step - loss: 0.0783 - acc: 0.9709 - val_loss: 0.0651 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00603: val_acc did not improve from 0.98734\n",
      "Epoch 604/1000\n",
      "134200/134200 [==============================] - 36s 272us/step - loss: 0.0793 - acc: 0.9705 - val_loss: 0.0730 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00604: val_acc did not improve from 0.98734\n",
      "Epoch 605/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0778 - acc: 0.9712 - val_loss: 0.0822 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00605: val_acc did not improve from 0.98734\n",
      "Epoch 606/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0784 - acc: 0.9711 - val_loss: 0.0843 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00606: val_acc did not improve from 0.98734\n",
      "Epoch 607/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0793 - acc: 0.9706 - val_loss: 0.0708 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00607: val_acc did not improve from 0.98734\n",
      "Epoch 608/1000\n",
      "134200/134200 [==============================] - 39s 287us/step - loss: 0.0784 - acc: 0.9709 - val_loss: 0.0618 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00608: val_acc did not improve from 0.98734\n",
      "Epoch 609/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0785 - acc: 0.9712 - val_loss: 0.0667 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00609: val_acc did not improve from 0.98734\n",
      "Epoch 610/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0793 - acc: 0.9704 - val_loss: 0.0647 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00610: val_acc did not improve from 0.98734\n",
      "Epoch 611/1000\n",
      "134200/134200 [==============================] - 46s 340us/step - loss: 0.0782 - acc: 0.9710 - val_loss: 0.0651 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00611: val_acc did not improve from 0.98734\n",
      "Epoch 612/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0791 - acc: 0.9704 - val_loss: 0.0691 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00612: val_acc did not improve from 0.98734\n",
      "Epoch 613/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0782 - acc: 0.9707 - val_loss: 0.0666 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00613: val_acc did not improve from 0.98734\n",
      "Epoch 614/1000\n",
      "134200/134200 [==============================] - 38s 280us/step - loss: 0.0786 - acc: 0.9709 - val_loss: 0.0620 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00614: val_acc did not improve from 0.98734\n",
      "Epoch 615/1000\n",
      "134200/134200 [==============================] - 49s 362us/step - loss: 0.0785 - acc: 0.9707 - val_loss: 0.0718 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00615: val_acc did not improve from 0.98734\n",
      "Epoch 616/1000\n",
      "134200/134200 [==============================] - 50s 374us/step - loss: 0.0782 - acc: 0.9709 - val_loss: 0.0699 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00616: val_acc did not improve from 0.98734\n",
      "Epoch 617/1000\n",
      "134200/134200 [==============================] - 49s 368us/step - loss: 0.0777 - acc: 0.9710 - val_loss: 0.0603 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00617: val_acc did not improve from 0.98734\n",
      "Epoch 618/1000\n",
      "134200/134200 [==============================] - 53s 392us/step - loss: 0.0786 - acc: 0.9709 - val_loss: 0.0652 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00618: val_acc did not improve from 0.98734\n",
      "Epoch 619/1000\n",
      "134200/134200 [==============================] - 53s 397us/step - loss: 0.0787 - acc: 0.9713 - val_loss: 0.0652 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00619: val_acc did not improve from 0.98734\n",
      "Epoch 620/1000\n",
      "134200/134200 [==============================] - 50s 370us/step - loss: 0.0794 - acc: 0.9709 - val_loss: 0.0585 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00620: val_acc did not improve from 0.98734\n",
      "Epoch 621/1000\n",
      "134200/134200 [==============================] - 50s 374us/step - loss: 0.0795 - acc: 0.9703 - val_loss: 0.0663 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00621: val_acc did not improve from 0.98734\n",
      "Epoch 622/1000\n",
      "134200/134200 [==============================] - 50s 374us/step - loss: 0.0778 - acc: 0.9712 - val_loss: 0.0692 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00622: val_acc did not improve from 0.98734\n",
      "Epoch 623/1000\n",
      "134200/134200 [==============================] - 48s 358us/step - loss: 0.0776 - acc: 0.9717 - val_loss: 0.0841 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00623: val_acc did not improve from 0.98734\n",
      "Epoch 624/1000\n",
      "134200/134200 [==============================] - 48s 355us/step - loss: 0.0789 - acc: 0.9707 - val_loss: 0.0774 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00624: val_acc did not improve from 0.98734\n",
      "Epoch 625/1000\n",
      "134200/134200 [==============================] - 54s 403us/step - loss: 0.0788 - acc: 0.9703 - val_loss: 0.0655 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00625: val_acc did not improve from 0.98734\n",
      "Epoch 626/1000\n",
      "134200/134200 [==============================] - 48s 359us/step - loss: 0.0789 - acc: 0.9709 - val_loss: 0.0610 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00626: val_acc did not improve from 0.98734\n",
      "Epoch 627/1000\n",
      "134200/134200 [==============================] - 3649s 27ms/step - loss: 0.0785 - acc: 0.9711 - val_loss: 0.0600 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00627: val_acc did not improve from 0.98734\n",
      "Epoch 628/1000\n",
      "134200/134200 [==============================] - 40s 297us/step - loss: 0.0795 - acc: 0.9706 - val_loss: 0.0630 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00628: val_acc did not improve from 0.98734\n",
      "Epoch 629/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0784 - acc: 0.9712 - val_loss: 0.0682 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00629: val_acc did not improve from 0.98734\n",
      "Epoch 630/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 35s 264us/step - loss: 0.0791 - acc: 0.9705 - val_loss: 0.0745 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00630: val_acc did not improve from 0.98734\n",
      "Epoch 631/1000\n",
      "134200/134200 [==============================] - 35s 264us/step - loss: 0.0794 - acc: 0.9708 - val_loss: 0.0585 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00631: val_acc did not improve from 0.98734\n",
      "Epoch 632/1000\n",
      "134200/134200 [==============================] - 35s 264us/step - loss: 0.0783 - acc: 0.9710 - val_loss: 0.0608 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00632: val_acc did not improve from 0.98734\n",
      "Epoch 633/1000\n",
      "134200/134200 [==============================] - 36s 267us/step - loss: 0.0788 - acc: 0.9710 - val_loss: 0.0625 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00633: val_acc did not improve from 0.98734\n",
      "Epoch 634/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0785 - acc: 0.9710 - val_loss: 0.0642 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00634: val_acc did not improve from 0.98734\n",
      "Epoch 635/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0778 - acc: 0.9715 - val_loss: 0.0757 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00635: val_acc did not improve from 0.98734\n",
      "Epoch 636/1000\n",
      "134200/134200 [==============================] - 39s 292us/step - loss: 0.0764 - acc: 0.9715 - val_loss: 0.0607 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00636: val_acc did not improve from 0.98734\n",
      "Epoch 637/1000\n",
      "134200/134200 [==============================] - 37s 277us/step - loss: 0.0778 - acc: 0.9708 - val_loss: 0.0593 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00637: val_acc did not improve from 0.98734\n",
      "Epoch 638/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0788 - acc: 0.9712 - val_loss: 0.0561 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00638: val_acc did not improve from 0.98734\n",
      "Epoch 639/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0774 - acc: 0.9715 - val_loss: 0.0786 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00639: val_acc did not improve from 0.98734\n",
      "Epoch 640/1000\n",
      "134200/134200 [==============================] - 36s 272us/step - loss: 0.0780 - acc: 0.9712 - val_loss: 0.0648 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00640: val_acc did not improve from 0.98734\n",
      "Epoch 641/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0779 - acc: 0.9711 - val_loss: 0.0744 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00641: val_acc did not improve from 0.98734\n",
      "Epoch 642/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0776 - acc: 0.9714 - val_loss: 0.0753 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00642: val_acc did not improve from 0.98734\n",
      "Epoch 643/1000\n",
      "134200/134200 [==============================] - 36s 269us/step - loss: 0.0785 - acc: 0.9708 - val_loss: 0.0590 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00643: val_acc did not improve from 0.98734\n",
      "Epoch 644/1000\n",
      "134200/134200 [==============================] - 38s 283us/step - loss: 0.0776 - acc: 0.9712 - val_loss: 0.0643 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00644: val_acc did not improve from 0.98734\n",
      "Epoch 645/1000\n",
      "134200/134200 [==============================] - 42s 310us/step - loss: 0.0770 - acc: 0.9714 - val_loss: 0.0578 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00645: val_acc did not improve from 0.98734\n",
      "Epoch 646/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0791 - acc: 0.9710 - val_loss: 0.0688 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00646: val_acc did not improve from 0.98734\n",
      "Epoch 647/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0779 - acc: 0.9712 - val_loss: 0.0605 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00647: val_acc did not improve from 0.98734\n",
      "Epoch 648/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0780 - acc: 0.9711 - val_loss: 0.0727 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00648: val_acc did not improve from 0.98734\n",
      "Epoch 649/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0778 - acc: 0.9716 - val_loss: 0.0611 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00649: val_acc did not improve from 0.98734\n",
      "Epoch 650/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0787 - acc: 0.9703 - val_loss: 0.0580 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00650: val_acc did not improve from 0.98734\n",
      "Epoch 651/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0774 - acc: 0.9712 - val_loss: 0.1193 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00651: val_acc did not improve from 0.98734\n",
      "Epoch 652/1000\n",
      "134200/134200 [==============================] - 43s 322us/step - loss: 0.0776 - acc: 0.9714 - val_loss: 0.0579 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00652: val_acc did not improve from 0.98734\n",
      "Epoch 653/1000\n",
      "134200/134200 [==============================] - 41s 306us/step - loss: 0.0778 - acc: 0.9712 - val_loss: 0.0607 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00653: val_acc did not improve from 0.98734\n",
      "Epoch 654/1000\n",
      "134200/134200 [==============================] - 41s 302us/step - loss: 0.0773 - acc: 0.9715 - val_loss: 0.0725 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00654: val_acc did not improve from 0.98734\n",
      "Epoch 655/1000\n",
      "134200/134200 [==============================] - 37s 276us/step - loss: 0.0772 - acc: 0.9718 - val_loss: 0.0579 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00655: val_acc did not improve from 0.98734\n",
      "Epoch 656/1000\n",
      "134200/134200 [==============================] - 36s 272us/step - loss: 0.0788 - acc: 0.9711 - val_loss: 0.0560 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00656: val_acc did not improve from 0.98734\n",
      "Epoch 657/1000\n",
      "134200/134200 [==============================] - 37s 273us/step - loss: 0.0780 - acc: 0.9709 - val_loss: 0.0801 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00657: val_acc did not improve from 0.98734\n",
      "Epoch 658/1000\n",
      "134200/134200 [==============================] - 37s 272us/step - loss: 0.0768 - acc: 0.9718 - val_loss: 0.0549 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00658: val_acc did not improve from 0.98734\n",
      "Epoch 659/1000\n",
      "134200/134200 [==============================] - 37s 274us/step - loss: 0.0780 - acc: 0.9715 - val_loss: 0.0524 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00659: val_acc did not improve from 0.98734\n",
      "Epoch 660/1000\n",
      "134200/134200 [==============================] - 39s 294us/step - loss: 0.0782 - acc: 0.9713 - val_loss: 0.0769 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00660: val_acc did not improve from 0.98734\n",
      "Epoch 661/1000\n",
      "134200/134200 [==============================] - 37s 277us/step - loss: 0.0776 - acc: 0.9712 - val_loss: 0.0654 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00661: val_acc did not improve from 0.98734\n",
      "Epoch 662/1000\n",
      "134200/134200 [==============================] - 36s 271us/step - loss: 0.0772 - acc: 0.9715 - val_loss: 0.0876 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00662: val_acc did not improve from 0.98734\n",
      "Epoch 663/1000\n",
      "134200/134200 [==============================] - 41s 306us/step - loss: 0.0788 - acc: 0.9706 - val_loss: 0.0640 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00663: val_acc did not improve from 0.98734\n",
      "Epoch 664/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0767 - acc: 0.9718 - val_loss: 0.0632 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00664: val_acc did not improve from 0.98734\n",
      "Epoch 665/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0784 - acc: 0.9706 - val_loss: 0.0572 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00665: val_acc did not improve from 0.98734\n",
      "Epoch 666/1000\n",
      "134200/134200 [==============================] - 37s 277us/step - loss: 0.0778 - acc: 0.9712 - val_loss: 0.0556 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00666: val_acc did not improve from 0.98734\n",
      "Epoch 667/1000\n",
      "134200/134200 [==============================] - 38s 281us/step - loss: 0.0783 - acc: 0.9710 - val_loss: 0.0622 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00667: val_acc did not improve from 0.98734\n",
      "Epoch 668/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0776 - acc: 0.9714 - val_loss: 0.0650 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00668: val_acc did not improve from 0.98734\n",
      "Epoch 669/1000\n",
      "134200/134200 [==============================] - 37s 277us/step - loss: 0.0778 - acc: 0.9714 - val_loss: 0.0952 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00669: val_acc did not improve from 0.98734\n",
      "Epoch 670/1000\n",
      "134200/134200 [==============================] - 37s 278us/step - loss: 0.0771 - acc: 0.9714 - val_loss: 0.0840 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00670: val_acc did not improve from 0.98734\n",
      "Epoch 671/1000\n",
      "134200/134200 [==============================] - 40s 296us/step - loss: 0.0764 - acc: 0.9717 - val_loss: 0.0672 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00671: val_acc did not improve from 0.98734\n",
      "Epoch 672/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 39s 291us/step - loss: 0.0788 - acc: 0.9709 - val_loss: 0.0652 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00672: val_acc did not improve from 0.98734\n",
      "Epoch 673/1000\n",
      "134200/134200 [==============================] - 38s 280us/step - loss: 0.0771 - acc: 0.9715 - val_loss: 0.0602 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00673: val_acc did not improve from 0.98734\n",
      "Epoch 674/1000\n",
      "134200/134200 [==============================] - 43s 319us/step - loss: 0.0764 - acc: 0.9718 - val_loss: 0.0576 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00674: val_acc did not improve from 0.98734\n",
      "Epoch 675/1000\n",
      "134200/134200 [==============================] - 50s 376us/step - loss: 0.0768 - acc: 0.9720 - val_loss: 0.1078 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00675: val_acc did not improve from 0.98734\n",
      "Epoch 676/1000\n",
      "134200/134200 [==============================] - 6669s 50ms/step - loss: 0.0772 - acc: 0.9714 - val_loss: 0.0656 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00676: val_acc did not improve from 0.98734\n",
      "Epoch 677/1000\n",
      "134200/134200 [==============================] - 32s 241us/step - loss: 0.0770 - acc: 0.9714 - val_loss: 0.0582 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00677: val_acc did not improve from 0.98734\n",
      "Epoch 678/1000\n",
      "134200/134200 [==============================] - 116s 861us/step - loss: 0.0773 - acc: 0.9716 - val_loss: 0.0871 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00678: val_acc did not improve from 0.98734\n",
      "Epoch 679/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0771 - acc: 0.9713 - val_loss: 0.0760 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00679: val_acc did not improve from 0.98734\n",
      "Epoch 680/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0765 - acc: 0.9718 - val_loss: 0.0660 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00680: val_acc did not improve from 0.98734\n",
      "Epoch 681/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0767 - acc: 0.9719 - val_loss: 0.2909 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00681: val_acc did not improve from 0.98734\n",
      "Epoch 682/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0770 - acc: 0.9715 - val_loss: 0.0661 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00682: val_acc did not improve from 0.98734\n",
      "Epoch 683/1000\n",
      "134200/134200 [==============================] - 39s 290us/step - loss: 0.0775 - acc: 0.9715 - val_loss: 0.0556 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00683: val_acc did not improve from 0.98734\n",
      "Epoch 684/1000\n",
      "134200/134200 [==============================] - 35s 262us/step - loss: 0.0768 - acc: 0.9721 - val_loss: 0.0658 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00684: val_acc did not improve from 0.98734\n",
      "Epoch 685/1000\n",
      "134200/134200 [==============================] - 34s 254us/step - loss: 0.0770 - acc: 0.9712 - val_loss: 0.0547 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00685: val_acc did not improve from 0.98734\n",
      "Epoch 686/1000\n",
      "134200/134200 [==============================] - 33s 246us/step - loss: 0.0771 - acc: 0.9713 - val_loss: 0.0549 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00686: val_acc did not improve from 0.98734\n",
      "Epoch 687/1000\n",
      "134200/134200 [==============================] - 37s 277us/step - loss: 0.0765 - acc: 0.9717 - val_loss: 0.0594 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00687: val_acc did not improve from 0.98734\n",
      "Epoch 688/1000\n",
      "134200/134200 [==============================] - 29s 220us/step - loss: 0.0764 - acc: 0.9713 - val_loss: 0.0576 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00688: val_acc did not improve from 0.98734\n",
      "Epoch 689/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0771 - acc: 0.9710 - val_loss: 0.0529 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00689: val_acc did not improve from 0.98734\n",
      "Epoch 690/1000\n",
      "134200/134200 [==============================] - 31s 232us/step - loss: 0.0771 - acc: 0.9713 - val_loss: 0.0528 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00690: val_acc did not improve from 0.98734\n",
      "Epoch 691/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0758 - acc: 0.9719 - val_loss: 0.0779 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00691: val_acc did not improve from 0.98734\n",
      "Epoch 692/1000\n",
      "134200/134200 [==============================] - 37s 279us/step - loss: 0.0768 - acc: 0.9715 - val_loss: 0.0586 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00692: val_acc did not improve from 0.98734\n",
      "Epoch 693/1000\n",
      "134200/134200 [==============================] - 35s 260us/step - loss: 0.0775 - acc: 0.9711 - val_loss: 0.0702 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00693: val_acc did not improve from 0.98734\n",
      "Epoch 694/1000\n",
      "134200/134200 [==============================] - 39s 289us/step - loss: 0.0758 - acc: 0.9724 - val_loss: 0.0628 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00694: val_acc did not improve from 0.98734\n",
      "Epoch 695/1000\n",
      "134200/134200 [==============================] - 32s 235us/step - loss: 0.0769 - acc: 0.9718 - val_loss: 0.0647 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00695: val_acc did not improve from 0.98734\n",
      "Epoch 696/1000\n",
      "134200/134200 [==============================] - 31s 233us/step - loss: 0.0765 - acc: 0.9715 - val_loss: 0.0609 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00696: val_acc did not improve from 0.98734\n",
      "Epoch 697/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0766 - acc: 0.9715 - val_loss: 0.0892 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00697: val_acc did not improve from 0.98734\n",
      "Epoch 698/1000\n",
      "134200/134200 [==============================] - 33s 246us/step - loss: 0.0764 - acc: 0.9720 - val_loss: 0.0558 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00698: val_acc did not improve from 0.98734\n",
      "Epoch 699/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0774 - acc: 0.9713 - val_loss: 0.0710 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00699: val_acc did not improve from 0.98734\n",
      "Epoch 700/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0768 - acc: 0.9720 - val_loss: 0.0591 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00700: val_acc did not improve from 0.98734\n",
      "Epoch 701/1000\n",
      "134200/134200 [==============================] - 32s 237us/step - loss: 0.0761 - acc: 0.9720 - val_loss: 0.0601 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00701: val_acc did not improve from 0.98734\n",
      "Epoch 702/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0754 - acc: 0.9723 - val_loss: 0.0835 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00702: val_acc did not improve from 0.98734\n",
      "Epoch 703/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0771 - acc: 0.9715 - val_loss: 0.0622 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00703: val_acc did not improve from 0.98734\n",
      "Epoch 704/1000\n",
      "134200/134200 [==============================] - 32s 236us/step - loss: 0.0779 - acc: 0.9708 - val_loss: 0.0604 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00704: val_acc did not improve from 0.98734\n",
      "Epoch 705/1000\n",
      "134200/134200 [==============================] - 33s 244us/step - loss: 0.0767 - acc: 0.9715 - val_loss: 0.0568 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00705: val_acc did not improve from 0.98734\n",
      "Epoch 706/1000\n",
      "134200/134200 [==============================] - 32s 236us/step - loss: 0.0774 - acc: 0.9713 - val_loss: 0.0631 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00706: val_acc did not improve from 0.98734\n",
      "Epoch 707/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0773 - acc: 0.9715 - val_loss: 0.0695 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00707: val_acc did not improve from 0.98734\n",
      "Epoch 708/1000\n",
      "134200/134200 [==============================] - 35s 263us/step - loss: 0.0772 - acc: 0.9717 - val_loss: 0.0538 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00708: val_acc did not improve from 0.98734\n",
      "Epoch 709/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0768 - acc: 0.9717 - val_loss: 0.0689 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00709: val_acc did not improve from 0.98734\n",
      "Epoch 710/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0764 - acc: 0.9718 - val_loss: 0.0544 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00710: val_acc did not improve from 0.98734\n",
      "Epoch 711/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0773 - acc: 0.9715 - val_loss: 0.0626 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00711: val_acc did not improve from 0.98734\n",
      "Epoch 712/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0762 - acc: 0.9722 - val_loss: 0.0499 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00712: val_acc did not improve from 0.98734\n",
      "Epoch 713/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0773 - acc: 0.9717 - val_loss: 0.0737 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00713: val_acc did not improve from 0.98734\n",
      "Epoch 714/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0780 - acc: 0.9715 - val_loss: 0.0507 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00714: val_acc did not improve from 0.98734\n",
      "Epoch 715/1000\n",
      "134200/134200 [==============================] - 30s 225us/step - loss: 0.0765 - acc: 0.9718 - val_loss: 0.0571 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00715: val_acc did not improve from 0.98734\n",
      "Epoch 716/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0758 - acc: 0.9722 - val_loss: 0.0538 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00716: val_acc did not improve from 0.98734\n",
      "Epoch 717/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0767 - acc: 0.9716 - val_loss: 0.0554 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00717: val_acc did not improve from 0.98734\n",
      "Epoch 718/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0772 - acc: 0.9720 - val_loss: 0.0823 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00718: val_acc did not improve from 0.98734\n",
      "Epoch 719/1000\n",
      "134200/134200 [==============================] - 34s 251us/step - loss: 0.0776 - acc: 0.9714 - val_loss: 0.0926 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00719: val_acc did not improve from 0.98734\n",
      "Epoch 720/1000\n",
      "134200/134200 [==============================] - 34s 252us/step - loss: 0.0764 - acc: 0.9717 - val_loss: 0.0567 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00720: val_acc did not improve from 0.98734\n",
      "Epoch 721/1000\n",
      "134200/134200 [==============================] - 35s 261us/step - loss: 0.0768 - acc: 0.9720 - val_loss: 0.0598 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00721: val_acc did not improve from 0.98734\n",
      "Epoch 722/1000\n",
      "134200/134200 [==============================] - 34s 257us/step - loss: 0.0762 - acc: 0.9721 - val_loss: 0.0605 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00722: val_acc did not improve from 0.98734\n",
      "Epoch 723/1000\n",
      "134200/134200 [==============================] - 35s 258us/step - loss: 0.0767 - acc: 0.9716 - val_loss: 0.0570 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00723: val_acc did not improve from 0.98734\n",
      "Epoch 724/1000\n",
      "134200/134200 [==============================] - 39s 291us/step - loss: 0.0770 - acc: 0.9713 - val_loss: 0.0602 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00724: val_acc did not improve from 0.98734\n",
      "Epoch 725/1000\n",
      "134200/134200 [==============================] - 43s 322us/step - loss: 0.0763 - acc: 0.9722 - val_loss: 0.0617 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00725: val_acc did not improve from 0.98734\n",
      "Epoch 726/1000\n",
      "134200/134200 [==============================] - 50s 369us/step - loss: 0.0763 - acc: 0.9718 - val_loss: 0.0776 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00726: val_acc did not improve from 0.98734\n",
      "Epoch 727/1000\n",
      "134200/134200 [==============================] - 52s 388us/step - loss: 0.0767 - acc: 0.9713 - val_loss: 0.0554 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00727: val_acc did not improve from 0.98734\n",
      "Epoch 728/1000\n",
      "134200/134200 [==============================] - 36s 265us/step - loss: 0.0770 - acc: 0.9719 - val_loss: 0.0632 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00728: val_acc did not improve from 0.98734\n",
      "Epoch 729/1000\n",
      "134200/134200 [==============================] - 48s 361us/step - loss: 0.0765 - acc: 0.9718 - val_loss: 0.0711 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00729: val_acc did not improve from 0.98734\n",
      "Epoch 730/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0756 - acc: 0.9723 - val_loss: 0.0603 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00730: val_acc did not improve from 0.98734\n",
      "Epoch 731/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0762 - acc: 0.9723 - val_loss: 0.0578 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00731: val_acc did not improve from 0.98734\n",
      "Epoch 732/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0763 - acc: 0.9722 - val_loss: 0.0631 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00732: val_acc did not improve from 0.98734\n",
      "Epoch 733/1000\n",
      "134200/134200 [==============================] - 33s 248us/step - loss: 0.0756 - acc: 0.9726 - val_loss: 0.0629 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00733: val_acc did not improve from 0.98734\n",
      "Epoch 734/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.0754 - acc: 0.9724 - val_loss: 0.0581 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00734: val_acc did not improve from 0.98734\n",
      "Epoch 735/1000\n",
      "134200/134200 [==============================] - 32s 240us/step - loss: 0.0765 - acc: 0.9717 - val_loss: 0.0657 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00735: val_acc did not improve from 0.98734\n",
      "Epoch 736/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0757 - acc: 0.9721 - val_loss: 0.0825 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00736: val_acc did not improve from 0.98734\n",
      "Epoch 737/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0777 - acc: 0.9715 - val_loss: 0.0573 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00737: val_acc did not improve from 0.98734\n",
      "Epoch 738/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0773 - acc: 0.9720 - val_loss: 0.0651 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00738: val_acc did not improve from 0.98734\n",
      "Epoch 739/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0766 - acc: 0.9716 - val_loss: 0.0582 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00739: val_acc did not improve from 0.98734\n",
      "Epoch 740/1000\n",
      "134200/134200 [==============================] - 27s 205us/step - loss: 0.0762 - acc: 0.9722 - val_loss: 0.0957 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00740: val_acc did not improve from 0.98734\n",
      "Epoch 741/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0754 - acc: 0.9722 - val_loss: 0.0671 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00741: val_acc did not improve from 0.98734\n",
      "Epoch 742/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0765 - acc: 0.9722 - val_loss: 0.0566 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00742: val_acc did not improve from 0.98734\n",
      "Epoch 743/1000\n",
      "134200/134200 [==============================] - 33s 243us/step - loss: 0.0759 - acc: 0.9723 - val_loss: 0.0604 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00743: val_acc did not improve from 0.98734\n",
      "Epoch 744/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0763 - acc: 0.9723 - val_loss: 0.0582 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00744: val_acc did not improve from 0.98734\n",
      "Epoch 745/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0764 - acc: 0.9719 - val_loss: 0.0604 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00745: val_acc did not improve from 0.98734\n",
      "Epoch 746/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0770 - acc: 0.9718 - val_loss: 0.0556 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00746: val_acc did not improve from 0.98734\n",
      "Epoch 747/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0761 - acc: 0.9717 - val_loss: 0.0685 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00747: val_acc did not improve from 0.98734\n",
      "Epoch 748/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0767 - acc: 0.9717 - val_loss: 0.0621 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00748: val_acc did not improve from 0.98734\n",
      "Epoch 749/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0749 - acc: 0.9724 - val_loss: 0.0517 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00749: val_acc did not improve from 0.98734\n",
      "Epoch 750/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0759 - acc: 0.9719 - val_loss: 0.0558 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00750: val_acc did not improve from 0.98734\n",
      "Epoch 751/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0748 - acc: 0.9723 - val_loss: 0.1081 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00751: val_acc did not improve from 0.98734\n",
      "Epoch 752/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0759 - acc: 0.9720 - val_loss: 0.1189 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00752: val_acc did not improve from 0.98734\n",
      "Epoch 753/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0759 - acc: 0.9720 - val_loss: 0.0619 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00753: val_acc did not improve from 0.98734\n",
      "Epoch 754/1000\n",
      "134200/134200 [==============================] - 29s 212us/step - loss: 0.0762 - acc: 0.9722 - val_loss: 0.0525 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00754: val_acc did not improve from 0.98734\n",
      "Epoch 755/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0763 - acc: 0.9722 - val_loss: 0.0544 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00755: val_acc did not improve from 0.98734\n",
      "Epoch 756/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0763 - acc: 0.9721 - val_loss: 0.0617 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00756: val_acc did not improve from 0.98734\n",
      "Epoch 757/1000\n",
      "134200/134200 [==============================] - 32s 235us/step - loss: 0.0765 - acc: 0.9720 - val_loss: 0.0798 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00757: val_acc did not improve from 0.98734\n",
      "Epoch 758/1000\n",
      "134200/134200 [==============================] - 33s 248us/step - loss: 0.0760 - acc: 0.9722 - val_loss: 0.0498 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00758: val_acc did not improve from 0.98734\n",
      "Epoch 759/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0751 - acc: 0.9724 - val_loss: 0.0699 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00759: val_acc did not improve from 0.98734\n",
      "Epoch 760/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0762 - acc: 0.9726 - val_loss: 0.0596 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00760: val_acc did not improve from 0.98734\n",
      "Epoch 761/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0754 - acc: 0.9723 - val_loss: 0.0610 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00761: val_acc did not improve from 0.98734\n",
      "Epoch 762/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0759 - acc: 0.9719 - val_loss: 0.0596 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00762: val_acc did not improve from 0.98734\n",
      "Epoch 763/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0759 - acc: 0.9718 - val_loss: 0.0679 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00763: val_acc did not improve from 0.98734\n",
      "Epoch 764/1000\n",
      "134200/134200 [==============================] - 37s 275us/step - loss: 0.0753 - acc: 0.9725 - val_loss: 0.0611 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00764: val_acc did not improve from 0.98734\n",
      "Epoch 765/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0759 - acc: 0.9718 - val_loss: 0.0540 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00765: val_acc did not improve from 0.98734\n",
      "Epoch 766/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0747 - acc: 0.9729 - val_loss: 0.0571 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00766: val_acc did not improve from 0.98734\n",
      "Epoch 767/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0751 - acc: 0.9727 - val_loss: 0.0548 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00767: val_acc did not improve from 0.98734\n",
      "Epoch 768/1000\n",
      "134200/134200 [==============================] - 27s 202us/step - loss: 0.0755 - acc: 0.9724 - val_loss: 0.0641 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00768: val_acc did not improve from 0.98734\n",
      "Epoch 769/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0746 - acc: 0.9727 - val_loss: 0.0649 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00769: val_acc did not improve from 0.98734\n",
      "Epoch 770/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0761 - acc: 0.9718 - val_loss: 0.0621 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00770: val_acc did not improve from 0.98734\n",
      "Epoch 771/1000\n",
      "134200/134200 [==============================] - 30s 227us/step - loss: 0.0759 - acc: 0.9722 - val_loss: 0.0635 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00771: val_acc did not improve from 0.98734\n",
      "Epoch 772/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0758 - acc: 0.9721 - val_loss: 0.0507 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00772: val_acc did not improve from 0.98734\n",
      "Epoch 773/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0758 - acc: 0.9721 - val_loss: 0.0628 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00773: val_acc did not improve from 0.98734\n",
      "Epoch 774/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0759 - acc: 0.9719 - val_loss: 0.0494 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00774: val_acc did not improve from 0.98734\n",
      "Epoch 775/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.0756 - acc: 0.9720 - val_loss: 0.1066 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00775: val_acc did not improve from 0.98734\n",
      "Epoch 776/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0755 - acc: 0.9721 - val_loss: 0.1384 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00776: val_acc did not improve from 0.98734\n",
      "Epoch 777/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0752 - acc: 0.9725 - val_loss: 0.0593 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00777: val_acc did not improve from 0.98734\n",
      "Epoch 778/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0752 - acc: 0.9726 - val_loss: 0.0617 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00778: val_acc did not improve from 0.98734\n",
      "Epoch 779/1000\n",
      "134200/134200 [==============================] - 29s 212us/step - loss: 0.0745 - acc: 0.9725 - val_loss: 0.0549 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00779: val_acc did not improve from 0.98734\n",
      "Epoch 780/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0760 - acc: 0.9721 - val_loss: 0.0513 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00780: val_acc did not improve from 0.98734\n",
      "Epoch 781/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0755 - acc: 0.9725 - val_loss: 0.0593 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00781: val_acc did not improve from 0.98734\n",
      "Epoch 782/1000\n",
      "134200/134200 [==============================] - 30s 227us/step - loss: 0.0763 - acc: 0.9719 - val_loss: 0.0493 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00782: val_acc did not improve from 0.98734\n",
      "Epoch 783/1000\n",
      "134200/134200 [==============================] - 36s 272us/step - loss: 0.0768 - acc: 0.9718 - val_loss: 0.0496 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00783: val_acc did not improve from 0.98734\n",
      "Epoch 784/1000\n",
      "134200/134200 [==============================] - 38s 283us/step - loss: 0.0748 - acc: 0.9724 - val_loss: 0.0673 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00784: val_acc did not improve from 0.98734\n",
      "Epoch 785/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0755 - acc: 0.9717 - val_loss: 0.0559 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00785: val_acc did not improve from 0.98734\n",
      "Epoch 786/1000\n",
      "134200/134200 [==============================] - 40s 300us/step - loss: 0.0766 - acc: 0.9715 - val_loss: 0.0522 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00786: val_acc did not improve from 0.98734\n",
      "Epoch 787/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0752 - acc: 0.9722 - val_loss: 0.0571 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00787: val_acc did not improve from 0.98734\n",
      "Epoch 788/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.0752 - acc: 0.9722 - val_loss: 0.0502 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00788: val_acc did not improve from 0.98734\n",
      "Epoch 789/1000\n",
      "134200/134200 [==============================] - 35s 259us/step - loss: 0.0764 - acc: 0.9718 - val_loss: 0.0480 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00789: val_acc did not improve from 0.98734\n",
      "Epoch 790/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0752 - acc: 0.9724 - val_loss: 0.0588 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00790: val_acc did not improve from 0.98734\n",
      "Epoch 791/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0755 - acc: 0.9719 - val_loss: 0.0483 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00791: val_acc did not improve from 0.98734\n",
      "Epoch 792/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.0757 - acc: 0.9724 - val_loss: 0.0662 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00792: val_acc did not improve from 0.98734\n",
      "Epoch 793/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.0749 - acc: 0.9726 - val_loss: 0.0492 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00793: val_acc did not improve from 0.98734\n",
      "Epoch 794/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0750 - acc: 0.9724 - val_loss: 0.0606 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00794: val_acc did not improve from 0.98734\n",
      "Epoch 795/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0767 - acc: 0.9719 - val_loss: 0.0550 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00795: val_acc did not improve from 0.98734\n",
      "Epoch 796/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0761 - acc: 0.9720 - val_loss: 0.0779 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00796: val_acc did not improve from 0.98734\n",
      "Epoch 797/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0758 - acc: 0.9722 - val_loss: 0.0534 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00797: val_acc did not improve from 0.98734\n",
      "Epoch 798/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0759 - acc: 0.9722 - val_loss: 0.0622 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00798: val_acc did not improve from 0.98734\n",
      "Epoch 799/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0741 - acc: 0.9727 - val_loss: 0.0554 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00799: val_acc did not improve from 0.98734\n",
      "Epoch 800/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0752 - acc: 0.9719 - val_loss: 0.0520 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00800: val_acc did not improve from 0.98734\n",
      "Epoch 801/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0757 - acc: 0.9720 - val_loss: 0.0575 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00801: val_acc did not improve from 0.98734\n",
      "Epoch 802/1000\n",
      "134200/134200 [==============================] - 34s 252us/step - loss: 0.0756 - acc: 0.9723 - val_loss: 0.0516 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00802: val_acc did not improve from 0.98734\n",
      "Epoch 803/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0754 - acc: 0.9724 - val_loss: 0.0494 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00803: val_acc did not improve from 0.98734\n",
      "Epoch 804/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0755 - acc: 0.9725 - val_loss: 0.0626 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00804: val_acc did not improve from 0.98734\n",
      "Epoch 805/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0758 - acc: 0.9721 - val_loss: 0.0509 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00805: val_acc did not improve from 0.98734\n",
      "Epoch 806/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0768 - acc: 0.9716 - val_loss: 0.1003 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00806: val_acc did not improve from 0.98734\n",
      "Epoch 807/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0764 - acc: 0.9723 - val_loss: 0.0613 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00807: val_acc did not improve from 0.98734\n",
      "Epoch 808/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0746 - acc: 0.9727 - val_loss: 0.0638 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00808: val_acc did not improve from 0.98734\n",
      "Epoch 809/1000\n",
      "134200/134200 [==============================] - 30s 220us/step - loss: 0.0759 - acc: 0.9721 - val_loss: 0.0569 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00809: val_acc did not improve from 0.98734\n",
      "Epoch 810/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0756 - acc: 0.9721 - val_loss: 0.0772 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00810: val_acc did not improve from 0.98734\n",
      "Epoch 811/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0761 - acc: 0.9721 - val_loss: 0.0538 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00811: val_acc did not improve from 0.98734\n",
      "Epoch 812/1000\n",
      "134200/134200 [==============================] - 32s 237us/step - loss: 0.0747 - acc: 0.9720 - val_loss: 0.0545 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00812: val_acc did not improve from 0.98734\n",
      "Epoch 813/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0755 - acc: 0.9723 - val_loss: 0.1386 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00813: val_acc did not improve from 0.98734\n",
      "Epoch 814/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0755 - acc: 0.9723 - val_loss: 0.0549 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00814: val_acc did not improve from 0.98734\n",
      "Epoch 815/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0761 - acc: 0.9722 - val_loss: 0.0570 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00815: val_acc did not improve from 0.98734\n",
      "Epoch 816/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0759 - acc: 0.9722 - val_loss: 0.0674 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00816: val_acc did not improve from 0.98734\n",
      "Epoch 817/1000\n",
      "134200/134200 [==============================] - 35s 264us/step - loss: 0.0745 - acc: 0.9725 - val_loss: 0.0685 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00817: val_acc did not improve from 0.98734\n",
      "Epoch 818/1000\n",
      "134200/134200 [==============================] - 31s 229us/step - loss: 0.0765 - acc: 0.9720 - val_loss: 0.0613 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00818: val_acc did not improve from 0.98734\n",
      "Epoch 819/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0760 - acc: 0.9719 - val_loss: 0.0521 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00819: val_acc did not improve from 0.98734\n",
      "Epoch 820/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0747 - acc: 0.9727 - val_loss: 0.0577 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00820: val_acc did not improve from 0.98734\n",
      "Epoch 821/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0764 - acc: 0.9718 - val_loss: 0.0552 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00821: val_acc did not improve from 0.98734\n",
      "Epoch 822/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0757 - acc: 0.9722 - val_loss: 0.0553 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00822: val_acc did not improve from 0.98734\n",
      "Epoch 823/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0757 - acc: 0.9720 - val_loss: 0.0642 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00823: val_acc did not improve from 0.98734\n",
      "Epoch 824/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0747 - acc: 0.9729 - val_loss: 0.0619 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00824: val_acc did not improve from 0.98734\n",
      "Epoch 825/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0758 - acc: 0.9721 - val_loss: 0.0540 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00825: val_acc did not improve from 0.98734\n",
      "Epoch 826/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0758 - acc: 0.9725 - val_loss: 0.0603 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00826: val_acc did not improve from 0.98734\n",
      "Epoch 827/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0742 - acc: 0.9730 - val_loss: 0.0480 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00827: val_acc did not improve from 0.98734\n",
      "Epoch 828/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0765 - acc: 0.9721 - val_loss: 0.0497 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00828: val_acc did not improve from 0.98734\n",
      "Epoch 829/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0743 - acc: 0.9729 - val_loss: 0.0569 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00829: val_acc did not improve from 0.98734\n",
      "Epoch 830/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0758 - acc: 0.9720 - val_loss: 0.0538 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00830: val_acc did not improve from 0.98734\n",
      "Epoch 831/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0755 - acc: 0.9723 - val_loss: 0.0737 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00831: val_acc did not improve from 0.98734\n",
      "Epoch 832/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0756 - acc: 0.9721 - val_loss: 0.0606 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00832: val_acc did not improve from 0.98734\n",
      "Epoch 833/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0762 - acc: 0.9721 - val_loss: 0.0583 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00833: val_acc did not improve from 0.98734\n",
      "Epoch 834/1000\n",
      "134200/134200 [==============================] - 27s 205us/step - loss: 0.0756 - acc: 0.9722 - val_loss: 0.0485 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00834: val_acc did not improve from 0.98734\n",
      "Epoch 835/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0748 - acc: 0.9727 - val_loss: 0.0504 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00835: val_acc did not improve from 0.98734\n",
      "Epoch 836/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0748 - acc: 0.9728 - val_loss: 0.0582 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00836: val_acc did not improve from 0.98734\n",
      "Epoch 837/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0758 - acc: 0.9718 - val_loss: 0.0621 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00837: val_acc did not improve from 0.98734\n",
      "Epoch 838/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0756 - acc: 0.9725 - val_loss: 0.0911 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00838: val_acc did not improve from 0.98734\n",
      "Epoch 839/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0753 - acc: 0.9721 - val_loss: 0.0518 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00839: val_acc did not improve from 0.98734\n",
      "Epoch 840/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0760 - acc: 0.9720 - val_loss: 0.0680 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00840: val_acc did not improve from 0.98734\n",
      "Epoch 841/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0741 - acc: 0.9729 - val_loss: 0.0656 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00841: val_acc did not improve from 0.98734\n",
      "Epoch 842/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0745 - acc: 0.9727 - val_loss: 0.0711 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00842: val_acc did not improve from 0.98734\n",
      "Epoch 843/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0751 - acc: 0.9726 - val_loss: 0.0797 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00843: val_acc did not improve from 0.98734\n",
      "Epoch 844/1000\n",
      "134200/134200 [==============================] - 27s 205us/step - loss: 0.0754 - acc: 0.9722 - val_loss: 0.0864 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00844: val_acc did not improve from 0.98734\n",
      "Epoch 845/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0757 - acc: 0.9719 - val_loss: 0.0655 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00845: val_acc did not improve from 0.98734\n",
      "Epoch 846/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0750 - acc: 0.9726 - val_loss: 0.0537 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00846: val_acc did not improve from 0.98734\n",
      "Epoch 847/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0750 - acc: 0.9723 - val_loss: 0.0520 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00847: val_acc did not improve from 0.98734\n",
      "Epoch 848/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0753 - acc: 0.9724 - val_loss: 0.0535 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00848: val_acc did not improve from 0.98734\n",
      "Epoch 849/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0754 - acc: 0.9723 - val_loss: 0.0740 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00849: val_acc did not improve from 0.98734\n",
      "Epoch 850/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0753 - acc: 0.9722 - val_loss: 0.2592 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00850: val_acc did not improve from 0.98734\n",
      "Epoch 851/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0757 - acc: 0.9722 - val_loss: 0.0710 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00851: val_acc did not improve from 0.98734\n",
      "Epoch 852/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0738 - acc: 0.9729 - val_loss: 0.0732 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00852: val_acc did not improve from 0.98734\n",
      "Epoch 853/1000\n",
      "134200/134200 [==============================] - 28s 206us/step - loss: 0.0755 - acc: 0.9726 - val_loss: 0.0552 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00853: val_acc did not improve from 0.98734\n",
      "Epoch 854/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0749 - acc: 0.9724 - val_loss: 0.0571 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00854: val_acc did not improve from 0.98734\n",
      "Epoch 855/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0753 - acc: 0.9721 - val_loss: 0.0592 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00855: val_acc did not improve from 0.98734\n",
      "Epoch 856/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0759 - acc: 0.9717 - val_loss: 0.0514 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00856: val_acc did not improve from 0.98734\n",
      "Epoch 857/1000\n",
      "134200/134200 [==============================] - 28s 205us/step - loss: 0.0746 - acc: 0.9727 - val_loss: 0.0547 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00857: val_acc did not improve from 0.98734\n",
      "Epoch 858/1000\n",
      "134200/134200 [==============================] - 33s 243us/step - loss: 0.0762 - acc: 0.9721 - val_loss: 0.0769 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00858: val_acc did not improve from 0.98734\n",
      "Epoch 859/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0750 - acc: 0.9720 - val_loss: 0.0527 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00859: val_acc did not improve from 0.98734\n",
      "Epoch 860/1000\n",
      "134200/134200 [==============================] - 30s 226us/step - loss: 0.0753 - acc: 0.9725 - val_loss: 0.0666 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00860: val_acc did not improve from 0.98734\n",
      "Epoch 861/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0771 - acc: 0.9717 - val_loss: 0.0563 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00861: val_acc did not improve from 0.98734\n",
      "Epoch 862/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.0758 - acc: 0.9719 - val_loss: 0.0549 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00862: val_acc did not improve from 0.98734\n",
      "Epoch 863/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0754 - acc: 0.9722 - val_loss: 0.0467 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00863: val_acc did not improve from 0.98734\n",
      "Epoch 864/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0767 - acc: 0.9720 - val_loss: 0.0536 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00864: val_acc did not improve from 0.98734\n",
      "Epoch 865/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0753 - acc: 0.9721 - val_loss: 0.0509 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00865: val_acc did not improve from 0.98734\n",
      "Epoch 866/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0749 - acc: 0.9726 - val_loss: 0.0494 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00866: val_acc did not improve from 0.98734\n",
      "Epoch 867/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0749 - acc: 0.9726 - val_loss: 0.0632 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00867: val_acc did not improve from 0.98734\n",
      "Epoch 868/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0756 - acc: 0.9724 - val_loss: 0.0600 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00868: val_acc did not improve from 0.98734\n",
      "Epoch 869/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0753 - acc: 0.9718 - val_loss: 0.0650 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00869: val_acc did not improve from 0.98734\n",
      "Epoch 870/1000\n",
      "134200/134200 [==============================] - 27s 205us/step - loss: 0.0756 - acc: 0.9720 - val_loss: 0.0517 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00870: val_acc did not improve from 0.98734\n",
      "Epoch 871/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0749 - acc: 0.9724 - val_loss: 0.0525 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00871: val_acc did not improve from 0.98734\n",
      "Epoch 872/1000\n",
      "134200/134200 [==============================] - 27s 204us/step - loss: 0.0755 - acc: 0.9718 - val_loss: 0.0571 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00872: val_acc did not improve from 0.98734\n",
      "Epoch 873/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0768 - acc: 0.9718 - val_loss: 0.0547 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00873: val_acc did not improve from 0.98734\n",
      "Epoch 874/1000\n",
      "134200/134200 [==============================] - 28s 205us/step - loss: 0.0757 - acc: 0.9721 - val_loss: 0.0588 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00874: val_acc did not improve from 0.98734\n",
      "Epoch 875/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0749 - acc: 0.9727 - val_loss: 0.0502 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00875: val_acc did not improve from 0.98734\n",
      "Epoch 876/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0762 - acc: 0.9721 - val_loss: 0.0538 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00876: val_acc did not improve from 0.98734\n",
      "Epoch 877/1000\n",
      "134200/134200 [==============================] - 34s 257us/step - loss: 0.0762 - acc: 0.9720 - val_loss: 0.0568 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00877: val_acc did not improve from 0.98734\n",
      "Epoch 878/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0752 - acc: 0.9720 - val_loss: 0.0509 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00878: val_acc did not improve from 0.98734\n",
      "Epoch 879/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0750 - acc: 0.9720 - val_loss: 0.0558 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00879: val_acc did not improve from 0.98734\n",
      "Epoch 880/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0748 - acc: 0.9731 - val_loss: 0.0490 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00880: val_acc did not improve from 0.98734\n",
      "Epoch 881/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0745 - acc: 0.9726 - val_loss: 0.0476 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00881: val_acc did not improve from 0.98734\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0755 - acc: 0.9721 - val_loss: 0.0522 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00882: val_acc did not improve from 0.98734\n",
      "Epoch 883/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0752 - acc: 0.9719 - val_loss: 0.0595 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00883: val_acc did not improve from 0.98734\n",
      "Epoch 884/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0746 - acc: 0.9724 - val_loss: 0.0551 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00884: val_acc did not improve from 0.98734\n",
      "Epoch 885/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0754 - acc: 0.9720 - val_loss: 0.0628 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00885: val_acc did not improve from 0.98734\n",
      "Epoch 886/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0753 - acc: 0.9722 - val_loss: 0.0510 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00886: val_acc did not improve from 0.98734\n",
      "Epoch 887/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0765 - acc: 0.9720 - val_loss: 0.0791 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00887: val_acc did not improve from 0.98734\n",
      "Epoch 888/1000\n",
      "134200/134200 [==============================] - 32s 235us/step - loss: 0.0749 - acc: 0.9722 - val_loss: 0.0652 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00888: val_acc did not improve from 0.98734\n",
      "Epoch 889/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0758 - acc: 0.9721 - val_loss: 0.0560 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00889: val_acc did not improve from 0.98734\n",
      "Epoch 890/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0754 - acc: 0.9721 - val_loss: 0.0586 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00890: val_acc did not improve from 0.98734\n",
      "Epoch 891/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0754 - acc: 0.9721 - val_loss: 0.0594 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00891: val_acc did not improve from 0.98734\n",
      "Epoch 892/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0756 - acc: 0.9722 - val_loss: 0.0625 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00892: val_acc did not improve from 0.98734\n",
      "Epoch 893/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0742 - acc: 0.9731 - val_loss: 0.0499 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00893: val_acc did not improve from 0.98734\n",
      "Epoch 894/1000\n",
      "134200/134200 [==============================] - 28s 207us/step - loss: 0.0754 - acc: 0.9722 - val_loss: 0.0559 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00894: val_acc did not improve from 0.98734\n",
      "Epoch 895/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0759 - acc: 0.9720 - val_loss: 0.0533 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00895: val_acc did not improve from 0.98734\n",
      "Epoch 896/1000\n",
      "134200/134200 [==============================] - 28s 208us/step - loss: 0.0755 - acc: 0.9726 - val_loss: 0.0498 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00896: val_acc did not improve from 0.98734\n",
      "Epoch 897/1000\n",
      "134200/134200 [==============================] - 28s 205us/step - loss: 0.0748 - acc: 0.9723 - val_loss: 0.0567 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00897: val_acc did not improve from 0.98734\n",
      "Epoch 898/1000\n",
      "134200/134200 [==============================] - 27s 203us/step - loss: 0.0745 - acc: 0.9727 - val_loss: 0.1120 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00898: val_acc did not improve from 0.98734\n",
      "Epoch 899/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0749 - acc: 0.9725 - val_loss: 0.0467 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00899: val_acc did not improve from 0.98734\n",
      "Epoch 900/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0751 - acc: 0.9723 - val_loss: 0.0485 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00900: val_acc did not improve from 0.98734\n",
      "Epoch 901/1000\n",
      "134200/134200 [==============================] - 28s 209us/step - loss: 0.0758 - acc: 0.9720 - val_loss: 0.0533 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00901: val_acc did not improve from 0.98734\n",
      "Epoch 902/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0756 - acc: 0.9725 - val_loss: 0.5821 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00902: val_acc did not improve from 0.98734\n",
      "Epoch 903/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0741 - acc: 0.9727 - val_loss: 0.0498 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00903: val_acc did not improve from 0.98734\n",
      "Epoch 904/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0760 - acc: 0.9721 - val_loss: 0.1369 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00904: val_acc did not improve from 0.98734\n",
      "Epoch 905/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0754 - acc: 0.9724 - val_loss: 0.0757 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00905: val_acc did not improve from 0.98734\n",
      "Epoch 906/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0754 - acc: 0.9724 - val_loss: 0.0643 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00906: val_acc did not improve from 0.98734\n",
      "Epoch 907/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0770 - acc: 0.9722 - val_loss: 0.0479 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00907: val_acc did not improve from 0.98734\n",
      "Epoch 908/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0750 - acc: 0.9727 - val_loss: 0.0697 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00908: val_acc did not improve from 0.98734\n",
      "Epoch 909/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0757 - acc: 0.9720 - val_loss: 0.0606 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00909: val_acc did not improve from 0.98734\n",
      "Epoch 910/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0745 - acc: 0.9730 - val_loss: 0.0588 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00910: val_acc did not improve from 0.98734\n",
      "Epoch 911/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0759 - acc: 0.9721 - val_loss: 0.0644 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00911: val_acc did not improve from 0.98734\n",
      "Epoch 912/1000\n",
      "134200/134200 [==============================] - 30s 220us/step - loss: 0.0747 - acc: 0.9721 - val_loss: 0.0551 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00912: val_acc did not improve from 0.98734\n",
      "Epoch 913/1000\n",
      "134200/134200 [==============================] - 36s 268us/step - loss: 0.0750 - acc: 0.9725 - val_loss: 0.0738 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00913: val_acc did not improve from 0.98734\n",
      "Epoch 914/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0755 - acc: 0.9718 - val_loss: 0.0531 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00914: val_acc did not improve from 0.98734\n",
      "Epoch 915/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0752 - acc: 0.9720 - val_loss: 0.0549 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00915: val_acc did not improve from 0.98734\n",
      "Epoch 916/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0758 - acc: 0.9722 - val_loss: 0.0775 - val_acc: 0.9684\n",
      "\n",
      "Epoch 00916: val_acc did not improve from 0.98734\n",
      "Epoch 917/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0749 - acc: 0.9721 - val_loss: 0.0582 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00917: val_acc did not improve from 0.98734\n",
      "Epoch 918/1000\n",
      "134200/134200 [==============================] - 30s 226us/step - loss: 0.0748 - acc: 0.9727 - val_loss: 0.0761 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00918: val_acc did not improve from 0.98734\n",
      "Epoch 919/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0747 - acc: 0.9726 - val_loss: 0.0514 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00919: val_acc did not improve from 0.98734\n",
      "Epoch 920/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0764 - acc: 0.9721 - val_loss: 0.0634 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00920: val_acc did not improve from 0.98734\n",
      "Epoch 921/1000\n",
      "134200/134200 [==============================] - 29s 220us/step - loss: 0.0745 - acc: 0.9722 - val_loss: 0.0512 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00921: val_acc did not improve from 0.98734\n",
      "Epoch 922/1000\n",
      "134200/134200 [==============================] - 1154s 9ms/step - loss: 0.0749 - acc: 0.9727 - val_loss: 0.0555 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00922: val_acc did not improve from 0.98734\n",
      "Epoch 923/1000\n",
      "134200/134200 [==============================] - 34s 254us/step - loss: 0.0755 - acc: 0.9719 - val_loss: 0.0572 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00923: val_acc did not improve from 0.98734\n",
      "Epoch 924/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0757 - acc: 0.9721 - val_loss: 0.0593 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00924: val_acc did not improve from 0.98734\n",
      "Epoch 925/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0742 - acc: 0.9729 - val_loss: 0.0556 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00925: val_acc did not improve from 0.98734\n",
      "Epoch 926/1000\n",
      "134200/134200 [==============================] - 49s 367us/step - loss: 0.0744 - acc: 0.9723 - val_loss: 0.0505 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00926: val_acc did not improve from 0.98734\n",
      "Epoch 927/1000\n",
      "134200/134200 [==============================] - 35s 258us/step - loss: 0.0738 - acc: 0.9727 - val_loss: 0.0681 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00927: val_acc did not improve from 0.98734\n",
      "Epoch 928/1000\n",
      "134200/134200 [==============================] - 31s 233us/step - loss: 0.0763 - acc: 0.9723 - val_loss: 0.0675 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00928: val_acc did not improve from 0.98734\n",
      "Epoch 929/1000\n",
      "134200/134200 [==============================] - 31s 228us/step - loss: 0.0745 - acc: 0.9724 - val_loss: 0.0555 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00929: val_acc did not improve from 0.98734\n",
      "Epoch 930/1000\n",
      "134200/134200 [==============================] - 33s 245us/step - loss: 0.0739 - acc: 0.9729 - val_loss: 0.0589 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00930: val_acc did not improve from 0.98734\n",
      "Epoch 931/1000\n",
      "134200/134200 [==============================] - 36s 266us/step - loss: 0.0766 - acc: 0.9716 - val_loss: 0.0493 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00931: val_acc did not improve from 0.98734\n",
      "Epoch 932/1000\n",
      "134200/134200 [==============================] - 30s 222us/step - loss: 0.0764 - acc: 0.9721 - val_loss: 0.0968 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00932: val_acc did not improve from 0.98734\n",
      "Epoch 933/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0747 - acc: 0.9727 - val_loss: 0.0745 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00933: val_acc did not improve from 0.98734\n",
      "Epoch 934/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0748 - acc: 0.9727 - val_loss: 0.0530 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00934: val_acc did not improve from 0.98734\n",
      "Epoch 935/1000\n",
      "134200/134200 [==============================] - 30s 220us/step - loss: 0.0751 - acc: 0.9723 - val_loss: 0.0679 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00935: val_acc did not improve from 0.98734\n",
      "Epoch 936/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0739 - acc: 0.9732 - val_loss: 0.0536 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00936: val_acc did not improve from 0.98734\n",
      "Epoch 937/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.0754 - acc: 0.9721 - val_loss: 0.0634 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00937: val_acc did not improve from 0.98734\n",
      "Epoch 938/1000\n",
      "134200/134200 [==============================] - 31s 227us/step - loss: 0.0754 - acc: 0.9723 - val_loss: 0.1158 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00938: val_acc did not improve from 0.98734\n",
      "Epoch 939/1000\n",
      "134200/134200 [==============================] - 31s 234us/step - loss: 0.0743 - acc: 0.9728 - val_loss: 0.0531 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00939: val_acc did not improve from 0.98734\n",
      "Epoch 940/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0748 - acc: 0.9727 - val_loss: 0.0490 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00940: val_acc did not improve from 0.98734\n",
      "Epoch 941/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.0757 - acc: 0.9723 - val_loss: 0.0673 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00941: val_acc did not improve from 0.98734\n",
      "Epoch 942/1000\n",
      "134200/134200 [==============================] - 31s 229us/step - loss: 0.0756 - acc: 0.9723 - val_loss: 0.1333 - val_acc: 0.9473\n",
      "\n",
      "Epoch 00942: val_acc did not improve from 0.98734\n",
      "Epoch 943/1000\n",
      "134200/134200 [==============================] - 31s 230us/step - loss: 0.0759 - acc: 0.9724 - val_loss: 0.0578 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00943: val_acc did not improve from 0.98734\n",
      "Epoch 944/1000\n",
      "134200/134200 [==============================] - 28s 212us/step - loss: 0.0760 - acc: 0.9717 - val_loss: 0.1458 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00944: val_acc did not improve from 0.98734\n",
      "Epoch 945/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0753 - acc: 0.9724 - val_loss: 0.0538 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00945: val_acc did not improve from 0.98734\n",
      "Epoch 946/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0750 - acc: 0.9727 - val_loss: 0.0582 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00946: val_acc did not improve from 0.98734\n",
      "Epoch 947/1000\n",
      "134200/134200 [==============================] - 29s 217us/step - loss: 0.0739 - acc: 0.9727 - val_loss: 0.0564 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00947: val_acc did not improve from 0.98734\n",
      "Epoch 948/1000\n",
      "134200/134200 [==============================] - 29s 213us/step - loss: 0.0738 - acc: 0.9727 - val_loss: 0.0503 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00948: val_acc did not improve from 0.98734\n",
      "Epoch 949/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0748 - acc: 0.9729 - val_loss: 0.0581 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00949: val_acc did not improve from 0.98734\n",
      "Epoch 950/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0760 - acc: 0.9721 - val_loss: 0.0976 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00950: val_acc did not improve from 0.98734\n",
      "Epoch 951/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0749 - acc: 0.9727 - val_loss: 0.0595 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00951: val_acc did not improve from 0.98734\n",
      "Epoch 952/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.0739 - acc: 0.9734 - val_loss: 0.0540 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00952: val_acc did not improve from 0.98734\n",
      "Epoch 953/1000\n",
      "134200/134200 [==============================] - 34s 256us/step - loss: 0.0738 - acc: 0.9731 - val_loss: 0.0629 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00953: val_acc did not improve from 0.98734\n",
      "Epoch 954/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0750 - acc: 0.9722 - val_loss: 0.0560 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00954: val_acc did not improve from 0.98734\n",
      "Epoch 955/1000\n",
      "134200/134200 [==============================] - 31s 233us/step - loss: 0.0754 - acc: 0.9725 - val_loss: 0.0606 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00955: val_acc did not improve from 0.98734\n",
      "Epoch 956/1000\n",
      "134200/134200 [==============================] - 32s 236us/step - loss: 0.0740 - acc: 0.9724 - val_loss: 0.0688 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00956: val_acc did not improve from 0.98734\n",
      "Epoch 957/1000\n",
      "134200/134200 [==============================] - 33s 249us/step - loss: 0.0746 - acc: 0.9725 - val_loss: 0.0695 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00957: val_acc did not improve from 0.98734\n",
      "Epoch 958/1000\n",
      "134200/134200 [==============================] - 37s 278us/step - loss: 0.0743 - acc: 0.9726 - val_loss: 0.0589 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00958: val_acc did not improve from 0.98734\n",
      "Epoch 959/1000\n",
      "134200/134200 [==============================] - 34s 252us/step - loss: 0.0759 - acc: 0.9723 - val_loss: 0.0550 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00959: val_acc did not improve from 0.98734\n",
      "Epoch 960/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0748 - acc: 0.9727 - val_loss: 0.0706 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00960: val_acc did not improve from 0.98734\n",
      "Epoch 961/1000\n",
      "134200/134200 [==============================] - 30s 223us/step - loss: 0.0757 - acc: 0.9722 - val_loss: 0.1392 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00961: val_acc did not improve from 0.98734\n",
      "Epoch 962/1000\n",
      "134200/134200 [==============================] - 31s 233us/step - loss: 0.0748 - acc: 0.9726 - val_loss: 0.0589 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00962: val_acc did not improve from 0.98734\n",
      "Epoch 963/1000\n",
      "134200/134200 [==============================] - 30s 221us/step - loss: 0.0745 - acc: 0.9725 - val_loss: 0.0583 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00963: val_acc did not improve from 0.98734\n",
      "Epoch 964/1000\n",
      "134200/134200 [==============================] - 31s 229us/step - loss: 0.0753 - acc: 0.9722 - val_loss: 0.0703 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00964: val_acc did not improve from 0.98734\n",
      "Epoch 965/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0754 - acc: 0.9723 - val_loss: 0.0544 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00965: val_acc did not improve from 0.98734\n",
      "Epoch 966/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0752 - acc: 0.9725 - val_loss: 0.0724 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00966: val_acc did not improve from 0.98734\n",
      "Epoch 967/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0752 - acc: 0.9725 - val_loss: 0.0604 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00967: val_acc did not improve from 0.98734\n",
      "Epoch 968/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0744 - acc: 0.9725 - val_loss: 0.0582 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00968: val_acc did not improve from 0.98734\n",
      "Epoch 969/1000\n",
      "134200/134200 [==============================] - 31s 231us/step - loss: 0.0757 - acc: 0.9724 - val_loss: 0.0940 - val_acc: 0.9599\n",
      "\n",
      "Epoch 00969: val_acc did not improve from 0.98734\n",
      "Epoch 970/1000\n",
      "134200/134200 [==============================] - 29s 218us/step - loss: 0.0766 - acc: 0.9722 - val_loss: 0.0671 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00970: val_acc did not improve from 0.98734\n",
      "Epoch 971/1000\n",
      "134200/134200 [==============================] - 33s 243us/step - loss: 0.0751 - acc: 0.9722 - val_loss: 0.0545 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00971: val_acc did not improve from 0.98734\n",
      "Epoch 972/1000\n",
      "134200/134200 [==============================] - 33s 243us/step - loss: 0.0747 - acc: 0.9725 - val_loss: 0.1159 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00972: val_acc did not improve from 0.98734\n",
      "Epoch 973/1000\n",
      "134200/134200 [==============================] - 35s 263us/step - loss: 0.0739 - acc: 0.9728 - val_loss: 0.0591 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00973: val_acc did not improve from 0.98734\n",
      "Epoch 974/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0750 - acc: 0.9723 - val_loss: 0.0853 - val_acc: 0.9620\n",
      "\n",
      "Epoch 00974: val_acc did not improve from 0.98734\n",
      "Epoch 975/1000\n",
      "134200/134200 [==============================] - 30s 225us/step - loss: 0.0747 - acc: 0.9723 - val_loss: 0.0699 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00975: val_acc did not improve from 0.98734\n",
      "Epoch 976/1000\n",
      "134200/134200 [==============================] - 30s 225us/step - loss: 0.0741 - acc: 0.9729 - val_loss: 0.0644 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00976: val_acc did not improve from 0.98734\n",
      "Epoch 977/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0743 - acc: 0.9727 - val_loss: 0.0514 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00977: val_acc did not improve from 0.98734\n",
      "Epoch 978/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0747 - acc: 0.9727 - val_loss: 0.0503 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00978: val_acc did not improve from 0.98734\n",
      "Epoch 979/1000\n",
      "134200/134200 [==============================] - 29s 216us/step - loss: 0.0753 - acc: 0.9723 - val_loss: 0.0554 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00979: val_acc did not improve from 0.98734\n",
      "Epoch 980/1000\n",
      "134200/134200 [==============================] - 39s 288us/step - loss: 0.0755 - acc: 0.9724 - val_loss: 0.0633 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00980: val_acc did not improve from 0.98734\n",
      "Epoch 981/1000\n",
      "134200/134200 [==============================] - 42s 316us/step - loss: 0.0752 - acc: 0.9718 - val_loss: 0.0668 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00981: val_acc did not improve from 0.98734\n",
      "Epoch 982/1000\n",
      "134200/134200 [==============================] - 35s 261us/step - loss: 0.0743 - acc: 0.9727 - val_loss: 0.0530 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00982: val_acc did not improve from 0.98734\n",
      "Epoch 983/1000\n",
      "134200/134200 [==============================] - 30s 227us/step - loss: 0.0754 - acc: 0.9722 - val_loss: 0.0568 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00983: val_acc did not improve from 0.98734\n",
      "Epoch 984/1000\n",
      "134200/134200 [==============================] - 31s 235us/step - loss: 0.0750 - acc: 0.9724 - val_loss: 0.0684 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00984: val_acc did not improve from 0.98734\n",
      "Epoch 985/1000\n",
      "134200/134200 [==============================] - 31s 228us/step - loss: 0.0747 - acc: 0.9725 - val_loss: 0.0544 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00985: val_acc did not improve from 0.98734\n",
      "Epoch 986/1000\n",
      "134200/134200 [==============================] - 32s 239us/step - loss: 0.0747 - acc: 0.9725 - val_loss: 0.0516 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00986: val_acc did not improve from 0.98734\n",
      "Epoch 987/1000\n",
      "134200/134200 [==============================] - 32s 238us/step - loss: 0.0740 - acc: 0.9730 - val_loss: 0.0566 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00987: val_acc did not improve from 0.98734\n",
      "Epoch 988/1000\n",
      "134200/134200 [==============================] - 32s 239us/step - loss: 0.0746 - acc: 0.9728 - val_loss: 0.0646 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00988: val_acc did not improve from 0.98734\n",
      "Epoch 989/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0758 - acc: 0.9727 - val_loss: 0.0606 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00989: val_acc did not improve from 0.98734\n",
      "Epoch 990/1000\n",
      "134200/134200 [==============================] - 29s 214us/step - loss: 0.0740 - acc: 0.9727 - val_loss: 0.0601 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00990: val_acc did not improve from 0.98734\n",
      "Epoch 991/1000\n",
      "134200/134200 [==============================] - 29s 212us/step - loss: 0.0749 - acc: 0.9720 - val_loss: 0.0622 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00991: val_acc did not improve from 0.98734\n",
      "Epoch 992/1000\n",
      "134200/134200 [==============================] - 29s 219us/step - loss: 0.0751 - acc: 0.9723 - val_loss: 0.0554 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00992: val_acc did not improve from 0.98734\n",
      "Epoch 993/1000\n",
      "134200/134200 [==============================] - 29s 212us/step - loss: 0.0730 - acc: 0.9735 - val_loss: 0.0568 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00993: val_acc did not improve from 0.98734\n",
      "Epoch 994/1000\n",
      "134200/134200 [==============================] - 30s 224us/step - loss: 0.0749 - acc: 0.9723 - val_loss: 0.0666 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00994: val_acc did not improve from 0.98734\n",
      "Epoch 995/1000\n",
      "134200/134200 [==============================] - 29s 215us/step - loss: 0.0744 - acc: 0.9725 - val_loss: 0.0575 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00995: val_acc did not improve from 0.98734\n",
      "Epoch 996/1000\n",
      "134200/134200 [==============================] - 31s 229us/step - loss: 0.0743 - acc: 0.9728 - val_loss: 0.0560 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00996: val_acc did not improve from 0.98734\n",
      "Epoch 997/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0744 - acc: 0.9727 - val_loss: 0.0514 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00997: val_acc did not improve from 0.98734\n",
      "Epoch 998/1000\n",
      "134200/134200 [==============================] - 28s 210us/step - loss: 0.0757 - acc: 0.9721 - val_loss: 0.0531 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00998: val_acc did not improve from 0.98734\n",
      "Epoch 999/1000\n",
      "134200/134200 [==============================] - 28s 211us/step - loss: 0.0739 - acc: 0.9728 - val_loss: 0.0560 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00999: val_acc did not improve from 0.98734\n",
      "Epoch 1000/1000\n",
      "134200/134200 [==============================] - 32s 235us/step - loss: 0.0750 - acc: 0.9726 - val_loss: 0.0524 - val_acc: 0.9810\n",
      "\n",
      "Epoch 01000: val_acc did not improve from 0.98734\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,\n",
    "                 y_train,\n",
    "                 validation_data=(X_test, y_test),\n",
    "                 nb_epoch=epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 callbacks = [best_model],\n",
    "                 shuffle = True,\n",
    "                 verbose=1)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAFcCAYAAADF3ZMOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn0AAAH/CAYAAAAi42uDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['acc'], linewidth = 3)\n",
    "plt.title('Model Training Accuracy')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss'], linewidth = 3)\n",
    "plt.title('Model Training Loss')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('Untitled Folder')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.plot(hist.history['val_acc'], linewidth = 3)\n",
    "plt.plot(hist.history['acc'], linewidth = 3)\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Test', 'Train'], loc='lower right')\n",
    "plt.savefig('Untitled Folder')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred, y_test_labels=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(X_test)):\n",
    "    y_test_pred.append(np.argmax(model.predict(X_test[i:i+1])))\n",
    "    y_test_labels.append(np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Test Set\n",
      "      Mn2+  Mn3+  Mn4+\n",
      "Mn2+   157     0     0\n",
      "Mn3+     2   136     3\n",
      "Mn4+     0     4   172\n",
      "Accuracy: 98.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix of Test Set\")\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_pred=y_test_pred, y_true=y_test_labels))\n",
    "conf_matrix.columns = [\"Mn2+\", \"Mn3+\", \"Mn4+\" ]\n",
    "conf_matrix = pd.DataFrame.transpose(conf_matrix)\n",
    "conf_matrix.columns = [\"Mn2+\", \"Mn3+\", \"Mn4+\" ]\n",
    "conf_matrix = pd.DataFrame.transpose(conf_matrix)\n",
    "print(conf_matrix)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
